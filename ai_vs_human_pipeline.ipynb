{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc0e420",
   "metadata": {},
   "source": [
    "\n",
    "# AI vs Human Text Detector — End-to-End (Notebook Version)\n",
    "\n",
    "This notebook trains a lightweight attention-pooling neural network on sentence-level embeddings (100×768), ensembles across K folds, selects the best sentence→paragraph aggregator using the provided validation set, and generates a Kaggle-ready `submission.csv` with columns `id,y_prob`.\n",
    "\n",
    "**Expected files in the working directory:**\n",
    "- `train_ai.npy` and `train_human.npy` — shape `(N, 100, 768)`\n",
    "- `validation.jsonl` — each line: `{\"id\": ..., \"features\": [ [100x768], ... ], \"label\": 0/1}`\n",
    "- `test_features.jsonl` — each line: `{\"id\": ..., \"features\": [ [100x768], ... ]}`\n",
    "\n",
    "> Tip: If your environment has no internet access, ensure required packages are already installed. The model uses only: `torch`, `numpy`, `pandas`, `scikit-learn`, `tqdm`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7861b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Optional: Uncomment if you need to install locally (internet access required)\n",
    "# !pip install torch numpy pandas scikit-learn tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb5e49cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, json, math, random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def infer_device() -> torch.device:\n",
    "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "def exists(path: str) -> bool:\n",
    "    return Path(path).exists()\n",
    "\n",
    "def masked_softmax(scores: torch.Tensor, mask: torch.Tensor, dim: int = -1) -> torch.Tensor:\n",
    "    mask = mask.to(dtype=scores.dtype)\n",
    "    neg_inf = torch.finfo(scores.dtype).min\n",
    "    masked_scores = scores.masked_fill(mask == 0, neg_inf)\n",
    "    return F.softmax(masked_scores, dim=dim)\n",
    "\n",
    "def make_token_mask(x: torch.Tensor, eps: float = 1e-12) -> torch.Tensor:\n",
    "    # x: (B, T, D) -> (B, T) mask 1 for non-zero rows\n",
    "    return (x.abs().sum(dim=-1) > eps).to(x.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffa576c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==== Config ====\n",
    "SEED = 42\n",
    "FOLDS = 5            # increase for more stable ensemble\n",
    "EPOCHS = 12          # increase if underfitting\n",
    "BATCH_SIZE = 128\n",
    "LR = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "DIM = 768            # embedding dim\n",
    "MAX_TOKENS = 100     # tokens per sentence\n",
    "\n",
    "PATH_TRAIN_AI = \"data/train/train_ai.npy\"\n",
    "PATH_TRAIN_HU = \"data/train/train_human.npy\"\n",
    "PATH_VAL_JSONL = \"data/train/validation.jsonl\"\n",
    "PATH_TEST_JSONL = \"data/test/test_features.jsonl\"\n",
    "\n",
    "OUT_MODELS_DIR = Path(\"models\")\n",
    "OUT_MODELS_DIR.mkdir(exist_ok=True, parents=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea64d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SentenceDataset(Dataset):\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray = None):\n",
    "        self.X = X.astype(np.float32, copy=False)\n",
    "        self.y = y.astype(np.float32, copy=False) if y is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        x = self.X[idx]\n",
    "        if self.y is None:\n",
    "            return x\n",
    "        return x, self.y[idx]\n",
    "\n",
    "def load_training_arrays(ai_path=PATH_TRAIN_AI, human_path=PATH_TRAIN_HU) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    assert exists(ai_path), f\"Missing {ai_path}\"\n",
    "    assert exists(human_path), f\"Missing {human_path}\"\n",
    "    ai = np.load(ai_path)     # (N_ai, 100, 768)\n",
    "    hu = np.load(human_path)  # (N_h , 100, 768)\n",
    "    X = np.concatenate([ai, hu], axis=0)\n",
    "    y = np.concatenate([np.ones(len(ai), dtype=np.float32),\n",
    "                        np.zeros(len(hu), dtype=np.float32)], axis=0)\n",
    "    return X, y\n",
    "\n",
    "def _to_np_sentence(arr_like) -> np.ndarray:\n",
    "    a = np.array(arr_like, dtype=np.float32)\n",
    "    if a.ndim != 2:\n",
    "        a = a.reshape(MAX_TOKENS, -1)\n",
    "    return a\n",
    "\n",
    "def load_jsonl_validation(path=PATH_VAL_JSONL):\n",
    "    ids, feats, labels = [], [], []\n",
    "    assert exists(path), f\"Missing {path}\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            pid = obj.get(\"id\")\n",
    "            label = int(obj.get(\"label\"))\n",
    "            sents = obj.get(\"features\")\n",
    "            sentence_mats = [_to_np_sentence(s) for s in sents]\n",
    "            ids.append(pid)\n",
    "            feats.append(sentence_mats)\n",
    "            labels.append(label)\n",
    "    return ids, feats, labels\n",
    "\n",
    "def load_jsonl_test(path=PATH_TEST_JSONL):\n",
    "    ids, feats = [], []\n",
    "    assert exists(path), f\"Missing {path}\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            pid = obj.get(\"id\")\n",
    "            sents = obj.get(\"features\")\n",
    "            sentence_mats = [_to_np_sentence(s) for s in sents]\n",
    "            ids.append(pid)\n",
    "            feats.append(sentence_mats)\n",
    "    return ids, feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7a5b21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TokenAttention(nn.Module):\n",
    "    def __init__(self, dim: int, attn_hidden: int = 256, dropout: float = 0.1):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(dim, attn_hidden)\n",
    "        self.score = nn.Linear(attn_hidden, 1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, mask: torch.Tensor):\n",
    "        x = self.ln(x)\n",
    "        h = torch.tanh(self.proj(x))\n",
    "        h = self.dropout(h)\n",
    "        scores = self.score(h).squeeze(-1)      # (B, T)\n",
    "        weights = masked_softmax(scores, mask)  # (B, T)\n",
    "        pooled = torch.bmm(weights.unsqueeze(1), x).squeeze(1)  # (B, D)\n",
    "        return pooled, weights\n",
    "\n",
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, dim: int = 768, attn_hidden: int = 256, mlp_hidden: int = 512, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "        self.attn = TokenAttention(dim, attn_hidden=attn_hidden, dropout=dropout)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim, mlp_hidden),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(mlp_hidden, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mask = make_token_mask(x)\n",
    "        pooled, _ = self.attn(x, mask)\n",
    "        logits = self.mlp(pooled).squeeze(-1)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a9b25b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_loaders(X, y, idx_tr, idx_va, batch_size=BATCH_SIZE):\n",
    "    ds_tr = SentenceDataset(X[idx_tr], y[idx_tr])\n",
    "    ds_va = SentenceDataset(X[idx_va], y[idx_va])\n",
    "    return (\n",
    "        DataLoader(ds_tr, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True),\n",
    "        DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True),\n",
    "    )\n",
    "\n",
    "def train_one_fold(model, train_loader, valid_loader, device, epochs=EPOCHS, lr=LR,\n",
    "                   weight_decay=WEIGHT_DECAY, pos_weight=1.0, fold=0):\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=device))\n",
    "\n",
    "    best_auc = -1.0\n",
    "    best_state = None\n",
    "    oof_logits = []\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        # train\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for x, y in tqdm(train_loader, leave=False, desc=f\"[Fold {fold}] Train epoch {epoch}\"):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "                logits = model(x)\n",
    "                loss = criterion(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            train_loss += loss.item() * x.size(0)\n",
    "        scheduler.step()\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # valid\n",
    "        model.eval()\n",
    "        val_logits, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in DataLoader(valid_loader.dataset, batch_size=BATCH_SIZE, shuffle=False):\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                logits = model(x)\n",
    "                val_logits.append(logits.detach().cpu().numpy())\n",
    "                val_targets.append(y.detach().cpu().numpy())\n",
    "        val_logits = np.concatenate(val_logits)\n",
    "        val_targets = np.concatenate(val_targets)\n",
    "        val_probs = 1 / (1 + np.exp(-val_logits))\n",
    "        try:\n",
    "            val_auc = roc_auc_score(val_targets, val_probs)\n",
    "        except Exception:\n",
    "            val_auc = float(\"nan\")\n",
    "        oof_logits.append(val_logits)\n",
    "\n",
    "        if not math.isnan(val_auc) and val_auc > best_auc:\n",
    "            best_auc = val_auc\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        print(f\"[Fold {fold}] epoch {epoch:02d}  train_loss={train_loss:.4f}  val_auc={val_auc:.5f}\")\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    return model, np.concatenate(oof_logits), best_auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae30140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def logits_to_prob(logits: np.ndarray) -> np.ndarray:\n",
    "    return 1.0 / (1.0 + np.exp(-logits))\n",
    "\n",
    "def agg_prob_mean(probs): return float(np.mean(probs))\n",
    "def agg_prob_max(probs):  return float(np.max(probs))\n",
    "def agg_logit_mean(logits): return float(logits_to_prob(np.mean(logits)))\n",
    "\n",
    "def choose_best_aggregator(valid_ids, valid_feats, valid_labels, models, device):\n",
    "    aggregators = {\n",
    "        \"logit_mean\": lambda probs, logits: agg_logit_mean(logits),\n",
    "        \"prob_mean\":  lambda probs, logits: agg_prob_mean(probs),\n",
    "        \"prob_max\":   lambda probs, logits: agg_prob_max(probs),\n",
    "    }\n",
    "    aucs = {}\n",
    "    for name, agg in aggregators.items():\n",
    "        y_true, y_score = [], []\n",
    "        for pid, sents, label in zip(valid_ids, valid_feats, valid_labels):\n",
    "            sent_logits = []\n",
    "            with torch.no_grad():\n",
    "                for s in sents:\n",
    "                    x = torch.tensor(s, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "                    logits_per_model = []\n",
    "                    for m in models:\n",
    "                        m.eval()\n",
    "                        l = m(x).item()\n",
    "                        logits_per_model.append(l)\n",
    "                    sent_logits.append(np.mean(logits_per_model))\n",
    "            sent_probs = [logits_to_prob(l) for l in sent_logits]\n",
    "            y_true.append(label)\n",
    "            y_score.append(agg(sent_probs, sent_logits))\n",
    "        try:\n",
    "            auc = roc_auc_score(y_true, y_score)\n",
    "        except Exception:\n",
    "            auc = float(\"nan\")\n",
    "        aucs[name] = auc\n",
    "    best_name = max(aucs, key=lambda k: (aucs[k] if not math.isnan(aucs[k]) else -1e9))\n",
    "    print(\"Aggregator AUCs:\", aucs)\n",
    "    return best_name, aucs[best_name]\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_paragraph_scores(ids, feats, models, device, aggregator=\"logit_mean\"):\n",
    "    if aggregator == \"prob_mean\":\n",
    "        agg_fn = lambda probs, logits: agg_prob_mean(probs)\n",
    "    elif aggregator == \"prob_max\":\n",
    "        agg_fn = lambda probs, logits: agg_prob_max(probs)\n",
    "    else:\n",
    "        agg_fn = lambda probs, logits: agg_logit_mean(logits)\n",
    "\n",
    "    out_ids, out_probs = [], []\n",
    "    for pid, sents in zip(ids, feats):\n",
    "        sent_logits = []\n",
    "        for s in sents:\n",
    "            x = torch.tensor(s, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "            logits_per_model = []\n",
    "            for m in models:\n",
    "                m.eval()\n",
    "                l = m(x).item()\n",
    "                logits_per_model.append(l)\n",
    "            sent_logits.append(float(np.mean(logits_per_model)))\n",
    "        sent_probs = [logits_to_prob(l) for l in sent_logits]\n",
    "        p = agg_fn(sent_probs, sent_logits)\n",
    "        out_ids.append(pid)\n",
    "        out_probs.append(p)\n",
    "    return pd.DataFrame({\"id\": out_ids, \"y_prob\": out_probs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56eb910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Train arrays: (16322, 100, 768), labels: pos=8161, neg=8161\n",
      "pos_weight=1.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "[Fold 0] Train epoch 1:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 01  train_loss=0.4995  val_auc=0.91467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 2:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 02  train_loss=0.3671  val_auc=0.94713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 3:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 03  train_loss=0.3389  val_auc=0.94798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 4:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 04  train_loss=0.3108  val_auc=0.95658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 5:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 05  train_loss=0.3402  val_auc=0.95258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 6:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 06  train_loss=0.2993  val_auc=0.95877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 7:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 07  train_loss=0.2981  val_auc=0.95871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 8:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 08  train_loss=0.2970  val_auc=0.95824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 9:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 09  train_loss=0.2920  val_auc=0.95806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 10:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 10  train_loss=0.2884  val_auc=0.95911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 11:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 11  train_loss=0.2794  val_auc=0.95860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 0] Train epoch 12:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] epoch 12  train_loss=0.2789  val_auc=0.95882\n",
      "[Fold 0] best val AUC: 0.95911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "[Fold 1] Train epoch 1:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 01  train_loss=0.5108  val_auc=0.90117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 2:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 02  train_loss=0.3835  val_auc=0.92925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 3:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 03  train_loss=0.3425  val_auc=0.94436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 4:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 04  train_loss=0.3188  val_auc=0.94313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 5:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 05  train_loss=0.3178  val_auc=0.94946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 6:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 06  train_loss=0.2973  val_auc=0.95256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 7:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 07  train_loss=0.3020  val_auc=0.95390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 8:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 08  train_loss=0.2884  val_auc=0.95482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 9:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 09  train_loss=0.2852  val_auc=0.95493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 10:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 10  train_loss=0.2797  val_auc=0.95511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 11:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 11  train_loss=0.2799  val_auc=0.95555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1] Train epoch 12:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] epoch 12  train_loss=0.2755  val_auc=0.95569\n",
      "[Fold 1] best val AUC: 0.95569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "[Fold 2] Train epoch 1:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 01  train_loss=0.5014  val_auc=0.89947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 2:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 02  train_loss=0.3650  val_auc=0.93886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 3:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 03  train_loss=0.3430  val_auc=0.94411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 4:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 04  train_loss=0.3234  val_auc=0.94759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 5:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 05  train_loss=0.3083  val_auc=0.94964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 6:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 06  train_loss=0.2994  val_auc=0.95014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 7:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 07  train_loss=0.2941  val_auc=0.95086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 8:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 08  train_loss=0.2885  val_auc=0.95299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 9:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 09  train_loss=0.2898  val_auc=0.95299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 10:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 10  train_loss=0.2781  val_auc=0.95351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 11:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 11  train_loss=0.2757  val_auc=0.95364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2] Train epoch 12:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 2] epoch 12  train_loss=0.2798  val_auc=0.95369\n",
      "[Fold 2] best val AUC: 0.95369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "[Fold 3] Train epoch 1:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 01  train_loss=0.5028  val_auc=0.90848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 2:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 02  train_loss=0.3804  val_auc=0.93462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 3:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 03  train_loss=0.3330  val_auc=0.94549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 4:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 04  train_loss=0.3269  val_auc=0.94708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 5:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 05  train_loss=0.3089  val_auc=0.95193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 6:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 06  train_loss=0.2942  val_auc=0.95413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 7:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 07  train_loss=0.2888  val_auc=0.95491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 8:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 08  train_loss=0.2835  val_auc=0.95515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 9:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 09  train_loss=0.2774  val_auc=0.95557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 10:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 10  train_loss=0.2782  val_auc=0.95602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 11:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 11  train_loss=0.2773  val_auc=0.95631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3] Train epoch 12:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 3] epoch 12  train_loss=0.2738  val_auc=0.95633\n",
      "[Fold 3] best val AUC: 0.95633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:11: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=(device.type == \"cuda\"))\n",
      "[Fold 4] Train epoch 1:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 01  train_loss=0.4988  val_auc=0.92000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 2:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 02  train_loss=0.3769  val_auc=0.93977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 3:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 03  train_loss=0.3436  val_auc=0.95039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 4:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 04  train_loss=0.3203  val_auc=0.95376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 5:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 05  train_loss=0.3125  val_auc=0.95164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 6:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 06  train_loss=0.2999  val_auc=0.95765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 7:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 07  train_loss=0.2959  val_auc=0.95852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 8:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 08  train_loss=0.2826  val_auc=0.95937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 9:   0%|                           | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 09  train_loss=0.2841  val_auc=0.95918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 10:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 10  train_loss=0.2770  val_auc=0.95971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 11:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 11  train_loss=0.2738  val_auc=0.95987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4] Train epoch 12:   0%|                          | 0/103 [00:00<?, ?it/s]/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_69461/3019015327.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 4] epoch 12  train_loss=0.2759  val_auc=0.96003\n",
      "[Fold 4] best val AUC: 0.96003\n",
      "Mean val AUC across folds: 0.9569711046188811\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed_everything(SEED)\n",
    "device = infer_device()\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Load sentence-level arrays\n",
    "X, y = load_training_arrays()\n",
    "print(f\"Train arrays: {X.shape}, labels: pos={int(y.sum())}, neg={int(len(y)-y.sum())}\")\n",
    "\n",
    "pos, neg = y.sum(), len(y)-y.sum()\n",
    "pos_weight = max(neg / max(pos, 1.0), 1.0)\n",
    "print(f\"pos_weight={pos_weight:.3f}\")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "models, fold_aucs = [], []\n",
    "oof_sentence_logits = np.zeros_like(y, dtype=np.float32)\n",
    "\n",
    "for fold, (idx_tr, idx_va) in enumerate(skf.split(X, y)):\n",
    "    model = SentenceClassifier(dim=DIM, attn_hidden=256, mlp_hidden=512, dropout=0.2).to(device)\n",
    "    tr_loader, va_loader = get_loaders(X, y, idx_tr, idx_va, BATCH_SIZE)\n",
    "    model, val_logits, val_auc = train_one_fold(model, tr_loader, va_loader, device,\n",
    "                                                epochs=EPOCHS, lr=LR, pos_weight=pos_weight, fold=fold)\n",
    "    models.append(model)\n",
    "    oof_sentence_logits[idx_va] = val_logits[:len(idx_va)]\n",
    "    fold_aucs.append(val_auc)\n",
    "    torch.save(model.state_dict(), OUT_MODELS_DIR / f\"fold_{fold}.pt\")\n",
    "    print(f\"[Fold {fold}] best val AUC: {val_auc:.5f}\")\n",
    "\n",
    "print(\"Mean val AUC across folds:\", np.nanmean(fold_aucs))\n",
    "np.save(\"oof_sentence_preds.npy\", oof_sentence_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe71f8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregator AUCs: {'logit_mean': 0.95, 'prob_mean': 0.9400000000000001, 'prob_max': 0.97}\n",
      "Validation with aggregator='prob_max': AUC=0.97000  ACC@0.5=0.5000\n",
      "Selected aggregator: prob_max AUC: 0.97\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agg_name, agg_auc = \"logit_mean\", float(\"nan\")\n",
    "if exists(PATH_VAL_JSONL):\n",
    "    val_ids, val_feats, val_labels = load_jsonl_validation(PATH_VAL_JSONL)\n",
    "    agg_name, agg_auc = choose_best_aggregator(val_ids, val_feats, val_labels, models, device)\n",
    "    df_val = predict_paragraph_scores(val_ids, val_feats, models, device, aggregator=agg_name)\n",
    "    df_val[\"label\"] = val_labels\n",
    "    try:\n",
    "        val_auc_final = roc_auc_score(val_labels, df_val[\"y_prob\"])\n",
    "        val_acc = accuracy_score(val_labels, (df_val[\"y_prob\"] >= 0.5).astype(int))\n",
    "        print(f\"Validation with aggregator='{agg_name}': AUC={val_auc_final:.5f}  ACC@0.5={val_acc:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(\"Validation metric error:\", e)\n",
    "    df_val.to_csv(\"validation_preds.csv\", index=False)\n",
    "else:\n",
    "    print(\"validation.jsonl not found; defaulting to aggregator='logit_mean'\")\n",
    "print(\"Selected aggregator:\", agg_name, \"AUC:\", agg_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24d58947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.640365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>0.589388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>0.442631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>0.816809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>0.958217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    y_prob\n",
       "0  15  0.640365\n",
       "1  16  0.589388\n",
       "2  17  0.442631\n",
       "3  18  0.816809\n",
       "4  19  0.958217"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Kaggle submission to submission.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if exists(PATH_TEST_JSONL):\n",
    "    test_ids, test_feats = load_jsonl_test(PATH_TEST_JSONL)\n",
    "    df_sub = predict_paragraph_scores(test_ids, test_feats, models, device, aggregator=agg_name)\n",
    "    df_sub = df_sub[[\"id\", \"y_prob\"]]\n",
    "    df_sub.to_csv(\"submission.csv\", index=False)\n",
    "    display(df_sub.head())\n",
    "    print(\"Saved Kaggle submission to submission.csv\")\n",
    "else:\n",
    "    print(\"test_features.jsonl not found; skipping submission generation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
