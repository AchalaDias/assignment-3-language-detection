{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2u-pdhPZdZ8",
        "outputId": "a1b498c5-8e13-4a7e-ed5b-d45353c26f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: NVIDIA A100-SXM4-40GB (UUID: GPU-13b75609-9ebf-dbff-2bb3-aee89348f97b)\n",
            "Python 3.12.11\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L || echo \"No GPU detected\"\n",
        "!python --version\n",
        "\n",
        "import os, random, math, json, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "def seed_everything(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed);\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "seed_everything(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
        "# EDIT THESE to where you placed your files on Drive:\n",
        "DRIVE_BASE = Path(\"/content/drive/MyDrive\")  # <--- change if needed\n",
        "\n",
        "TRAIN_AI = DRIVE_BASE / \"train_ai.npy\"\n",
        "TRAIN_HU = DRIVE_BASE / \"train_human.npy\"\n",
        "VAL_JSONL = DRIVE_BASE / \"validation.jsonl\"\n",
        "TEST_JSONL = DRIVE_BASE / \"test_features.jsonl\"\n",
        "\n",
        "OUT_DIR = DRIVE_BASE / \"colab_outputs\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "# <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
        "\n",
        "for p in [TRAIN_AI, TRAIN_HU, VAL_JSONL, TEST_JSONL]:\n",
        "    assert p.exists(), f\"Missing: {p}\"\n",
        "print(\"All input files found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta5Gq4oViiae",
        "outputId": "23a52257-7f56-4546-9f3d-ba6ee898c134"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "All input files found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ujson"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DcXJUijDYHb",
        "outputId": "6370c202-2ded-4cef-f6f4-3f8b09bf9fdc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ujson in /usr/local/lib/python3.12/dist-packages (5.11.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ujson\n",
        "\n",
        "# A token row is padding if all dims are 0\n",
        "def compute_token_mask(x_2d: np.ndarray) -> np.ndarray:\n",
        "    # x_2d: (T=100, D=768)\n",
        "    return (np.abs(x_2d).sum(axis=1) > 0).astype(np.float32)\n",
        "\n",
        "def load_train_arrays(ai_path, hu_path):\n",
        "    ai = np.load(ai_path, allow_pickle=True).astype(np.float32)   # (Na,100,768)\n",
        "    hu = np.load(hu_path, allow_pickle=True).astype(np.float32)   # (Nh,100,768)\n",
        "    X = np.concatenate([ai, hu], axis=0)\n",
        "    y = np.concatenate([np.ones(len(ai), dtype=np.int64),\n",
        "                        np.zeros(len(hu), dtype=np.int64)], axis=0)\n",
        "    return X, y\n",
        "\n",
        "def read_grouped_jsonl(path, expect_label=False):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      ids: list of paragraph ids (length = num paragraphs)\n",
        "      mats: list of np.array of shape (S,100,768) per paragraph (S sentences)\n",
        "      labels: np.array [num paragraphs] if expect_label\n",
        "    \"\"\"\n",
        "    ids, mats, labels = [], [], []\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            obj = ujson.loads(line)\n",
        "            ids.append(obj[\"id\"])\n",
        "            feats = np.array(obj[\"features\"], dtype=np.float32)  # (S,100,768)\n",
        "            mats.append(feats)\n",
        "            if expect_label: labels.append(int(obj[\"label\"]))\n",
        "    if expect_label:\n",
        "        return np.array(ids), mats, np.array(labels)\n",
        "    return np.array(ids), mats\n"
      ],
      "metadata": {
        "id": "op4LMjpQDE_q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentenceDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Training dataset: (N,100,768) sentences with labels.\n",
        "    Optional simple augmentations: token dropout + light Gaussian noise.\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, aug=True, token_drop_p=0.1, noise_std=0.01):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.aug = aug\n",
        "        self.token_drop_p = token_drop_p\n",
        "        self.noise_std = noise_std\n",
        "\n",
        "    def __len__(self): return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.X[idx]  # (100,768)\n",
        "        y = self.y[idx]\n",
        "        m = compute_token_mask(x)  # (100,)\n",
        "\n",
        "        if self.aug:\n",
        "            # Randomly drop some valid tokens (set to 0)\n",
        "            if self.token_drop_p > 0:\n",
        "                valid_idx = np.where(m > 0.5)[0]\n",
        "                if len(valid_idx) > 0:\n",
        "                    k = max(1, int(len(valid_idx) * self.token_drop_p))\n",
        "                    drop = np.random.choice(valid_idx, size=k, replace=False)\n",
        "                    x = x.copy()\n",
        "                    x[drop] = 0.0\n",
        "                    m = compute_token_mask(x)\n",
        "\n",
        "            # Add tiny Gaussian noise to valid tokens\n",
        "            if self.noise_std > 0:\n",
        "                noise = np.random.normal(0, self.noise_std, size=x.shape).astype(np.float32)\n",
        "                x = x + noise * m[:,None]\n",
        "\n",
        "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.long), torch.from_numpy(m)\n",
        "\n",
        "class SentenceEvalDataset(Dataset):\n",
        "    \"\"\"\n",
        "    For validation/test: flattened sentences with paragraph id mapping.\n",
        "    \"\"\"\n",
        "    def __init__(self, mats, para_ids):\n",
        "        # flatten sentences, keep mapping to paragraph id\n",
        "        self.samples = []\n",
        "        for pid, para in zip(para_ids, mats):\n",
        "            for s in range(len(para)):\n",
        "                self.samples.append((para[s], pid))\n",
        "        self.n = len(self.samples)\n",
        "\n",
        "    def __len__(self): return self.n\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x, pid = self.samples[idx]  # (100,768)\n",
        "        m = compute_token_mask(x)\n",
        "        return torch.from_numpy(x), torch.from_numpy(m), pid\n"
      ],
      "metadata": {
        "id": "Jz4RPLteDebU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 100):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pos = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
        "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(pos * div)\n",
        "        pe[:, 1::2] = torch.cos(pos * div)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))  # (1, max_len, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, T, C)\n",
        "        T = x.size(1)\n",
        "        return x + self.pe[:, :T, :]\n",
        "\n",
        "class TokenTransformer(nn.Module):\n",
        "    def __init__(self, in_dim=768, model_dim=256, n_heads=8, ff_dim=512, n_layers=2, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.proj = nn.Linear(in_dim, model_dim)\n",
        "        self.posenc = PositionalEncoding(model_dim, max_len=100)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=n_heads,\n",
        "                                                   dim_feedforward=ff_dim, dropout=dropout,\n",
        "                                                   batch_first=True, activation=\"gelu\", norm_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "        self.pool_attn = nn.Sequential(\n",
        "            nn.Linear(model_dim, model_dim),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(model_dim, 1)\n",
        "        )\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(model_dim*2),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(model_dim*2, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "      # x: (B,T,768), mask: (B,T) where 1 = valid token\n",
        "      x = self.proj(x)                          # (B,T,C)\n",
        "      x = self.posenc(x)\n",
        "\n",
        "      pad_mask = ~mask.bool()                   # True where padding\n",
        "      h = self.encoder(x, src_key_padding_mask=pad_mask)  # (B,T,C)\n",
        "\n",
        "      # masked mean/max pooling\n",
        "      m = mask.unsqueeze(-1)                    # (B,T,1)\n",
        "      h_masked = h * m\n",
        "      denom = m.sum(dim=1).clamp(min=1.0)\n",
        "      mean_pool = h_masked.sum(dim=1) / denom\n",
        "\n",
        "      # use a fp16-safe negative value (fp16 min ≈ -65504)\n",
        "      NEG_LARGE = -1e4\n",
        "      max_pool = h.masked_fill(pad_mask.unsqueeze(-1), NEG_LARGE).max(dim=1).values\n",
        "\n",
        "      # attention pooling (learned)\n",
        "      attn_logits = self.pool_attn(h)           # (B,T,1)\n",
        "      attn_logits = attn_logits.masked_fill(pad_mask.unsqueeze(-1), NEG_LARGE)\n",
        "      attn = torch.softmax(attn_logits, dim=1)\n",
        "      attn_pool = (attn * h).sum(dim=1)\n",
        "\n",
        "      fused = torch.cat([0.5*(mean_pool+max_pool), attn_pool], dim=-1)  # (B,2C)\n",
        "      logit = self.head(fused).squeeze(-1)         # (B,)\n",
        "      return logit\n",
        "\n"
      ],
      "metadata": {
        "id": "VXIHoAI3Dg5n"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, optimizer, scaler, scheduler=None):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    for xb, yb, mb in loader:\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        yb = yb.float().to(device, non_blocking=True)\n",
        "        mb = mb.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast('cuda', enabled=(device==\"cuda\")):\n",
        "            logits = model(xb, mb)\n",
        "            loss = criterion(logits, yb)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        total_loss += loss.item() * xb.size(0)\n",
        "    return total_loss / len(loader.dataset)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_logits(model, loader):\n",
        "    model.eval()\n",
        "    all_logits = []\n",
        "    for batch in loader:\n",
        "        # batch is either:\n",
        "        #  - TRAIN/EVAL on fold: (x, y, mask)\n",
        "        #  - PARAGRAPH eval loaders: (x, mask, pid)\n",
        "        if len(batch) == 3:\n",
        "            a, b, c = batch\n",
        "            # mask is the one with shape (B, T)\n",
        "            if hasattr(b, \"ndim\") and b.ndim == 2:\n",
        "                xb, mb = a, b           # (x, mask, pid) case\n",
        "            elif hasattr(c, \"ndim\") and c.ndim == 2:\n",
        "                xb, mb = a, c           # (x, y, mask) case\n",
        "            else:\n",
        "                raise ValueError(\"Could not locate mask tensor in batch of length 3.\")\n",
        "        else:\n",
        "            # fallback: (x, mask)\n",
        "            xb, mb = batch\n",
        "\n",
        "        xb = xb.to(device, non_blocking=True)\n",
        "        mb = mb.to(device, non_blocking=True)\n",
        "\n",
        "        with torch.amp.autocast('cuda', enabled=(device == \"cuda\")):\n",
        "            logits = model(xb, mb)\n",
        "        all_logits.append(logits.detach().float().cpu())\n",
        "    return torch.cat(all_logits, dim=0).numpy()\n",
        "\n",
        "\n",
        "def probs_from_logits(logits):\n",
        "    return 1 / (1 + np.exp(-logits))\n"
      ],
      "metadata": {
        "id": "ErFKZqBfDlXj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparams (tweak as needed)\n",
        "EPOCHS = 8            # 10–12 if you have time\n",
        "BATCH_TRAIN = 64      # 64–96 on T4 is OK\n",
        "BATCH_EVAL  = 128\n",
        "LR = 2e-4\n",
        "WD = 1e-4\n",
        "MODEL_DIM = 256\n",
        "LAYERS = 2\n",
        "HEADS = 8\n",
        "FF = 512\n",
        "DROPOUT = 0.15\n",
        "\n",
        "# Load data\n",
        "X_raw, y = load_train_arrays(TRAIN_AI, TRAIN_HU)\n",
        "print(\"Train tensors:\", X_raw.shape, \"Pos:\", y.sum(), \"Neg:\", (y==0).sum())\n",
        "val_ids, val_mats, val_labels = read_grouped_jsonl(VAL_JSONL, expect_label=True)\n",
        "test_ids, test_mats = read_grouped_jsonl(TEST_JSONL, expect_label=False)\n",
        "print(\"Val paragraphs:\", len(val_ids), \"Test paragraphs:\", len(test_ids))\n",
        "\n",
        "# Build flattened datasets for validation/test sentence-level inference\n",
        "val_sent_ds  = SentenceEvalDataset(val_mats, val_ids)   # sentences with id mapping\n",
        "test_sent_ds = SentenceEvalDataset(test_mats, test_ids)\n",
        "\n",
        "val_loader_sent  = DataLoader(val_sent_ds,  batch_size=BATCH_EVAL, shuffle=False,\n",
        "                              num_workers=2, pin_memory=True, collate_fn=None)\n",
        "test_loader_sent = DataLoader(test_sent_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                              num_workers=2, pin_memory=True, collate_fn=None)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "oof_logits = np.zeros(len(X_raw), dtype=np.float32)\n",
        "val_prob_blend = np.zeros(len(val_sent_ds), dtype=np.float32)\n",
        "test_prob_blend = np.zeros(len(test_sent_ds), dtype=np.float32)\n",
        "\n",
        "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_raw, y), 1):\n",
        "    print(f\"\\n===== Fold {fold} / 5 =====\")\n",
        "    train_ds = SentenceDataset(X_raw[tr_idx], y[tr_idx], aug=True, token_drop_p=0.1, noise_std=0.01)\n",
        "    valid_ds = SentenceDataset(X_raw[va_idx], y[va_idx], aug=False)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_TRAIN, shuffle=True,\n",
        "                              num_workers=2, pin_memory=True, drop_last=True)\n",
        "    valid_loader = DataLoader(valid_ds, batch_size=BATCH_EVAL, shuffle=False,\n",
        "                              num_workers=2, pin_memory=True)\n",
        "\n",
        "    model = TokenTransformer(in_dim=768, model_dim=MODEL_DIM, n_heads=HEADS,\n",
        "                             ff_dim=FF, n_layers=LAYERS, dropout=DROPOUT).to(device)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "    # OneCycle or cosine works; OneCycle is simple here:\n",
        "    total_steps = EPOCHS * len(train_loader)\n",
        "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "        optimizer, max_lr=LR, total_steps=total_steps, pct_start=0.1, anneal_strategy=\"cos\"\n",
        "    )\n",
        "    scaler = torch.amp.GradScaler('cuda', enabled=(device==\"cuda\"))\n",
        "    best_auc, best_state = -1, None\n",
        "    patience, patience_ctr = 3, 0\n",
        "\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, scaler, scheduler)\n",
        "        # eval on fold's validation split\n",
        "        v_logits = predict_logits(model, valid_loader)\n",
        "        v_probs  = probs_from_logits(v_logits)\n",
        "        v_auc    = roc_auc_score(y[va_idx], v_probs)\n",
        "        v_acc    = accuracy_score(y[va_idx], (v_probs>=0.5).astype(int))\n",
        "        print(f\"Epoch {epoch:02d} | loss {train_loss:.4f} | val AUC {v_auc:.4f} | ACC {v_acc:.4f}\")\n",
        "\n",
        "        if v_auc > best_auc + 1e-4:\n",
        "            best_auc = v_auc\n",
        "            best_state = model.state_dict()\n",
        "            patience_ctr = 0\n",
        "        else:\n",
        "            patience_ctr += 1\n",
        "            if patience_ctr >= patience:\n",
        "                print(\"Early stopping.\")\n",
        "                break\n",
        "\n",
        "    # load best fold weights\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    # save fold model\n",
        "    fold_path = OUT_DIR / f\"transformer_fold{fold}.pt\"\n",
        "    torch.save(model.state_dict(), fold_path)\n",
        "    print(\"Saved:\", fold_path)\n",
        "\n",
        "    # OOF logits for train split\n",
        "    v_logits = predict_logits(model, valid_loader)\n",
        "    oof_logits[va_idx] = v_logits\n",
        "\n",
        "    # Predict validation/test sentences for paragraph aggregation\n",
        "    v_logits_sent = predict_logits(model, val_loader_sent)\n",
        "    t_logits_sent = predict_logits(model, test_loader_sent)\n",
        "\n",
        "    v_probs_sent = probs_from_logits(v_logits_sent)\n",
        "    t_probs_sent = probs_from_logits(t_logits_sent)\n",
        "\n",
        "    # Blend across folds by averaging probs\n",
        "    val_prob_blend  += v_probs_sent / skf.n_splits\n",
        "    test_prob_blend += t_probs_sent / skf.n_splits\n",
        "\n",
        "# OOF metrics\n",
        "oof_probs = probs_from_logits(oof_logits)\n",
        "oof_auc = roc_auc_score(y, oof_probs)\n",
        "oof_acc = accuracy_score(y, (oof_probs>=0.5).astype(int))\n",
        "print(f\"\\nOOF AUC: {oof_auc:.4f} | OOF ACC@0.5: {oof_acc:.4f}\")\n",
        "\n",
        "# Aggregate sentence probs to paragraph probs (mean; you can try median/max too)\n",
        "val_sent_df = pd.DataFrame({\"id\":[pid for _,_,pid in val_loader_sent.dataset], \"prob\":val_prob_blend})\n",
        "test_sent_df= pd.DataFrame({\"id\":[pid for _,_,pid in test_loader_sent.dataset], \"prob\":test_prob_blend})\n",
        "\n",
        "val_para = val_sent_df.groupby(\"id\")[\"prob\"].mean().reset_index()\n",
        "test_para= test_sent_df.groupby(\"id\")[\"prob\"].mean().reset_index()\n",
        "\n",
        "# Validation metrics at paragraph level\n",
        "val_df = pd.DataFrame({\"id\": val_ids, \"label\": val_labels}).groupby(\"id\")[\"label\"].mean().round().astype(int).reset_index()\n",
        "vv = val_para.merge(val_df, on=\"id\", how=\"left\")\n",
        "val_auc = roc_auc_score(vv[\"label\"].values, vv[\"prob\"].values)\n",
        "val_acc = accuracy_score(vv[\"label\"].values, (vv[\"prob\"].values>=0.5).astype(int))\n",
        "print(f\"Validation paragraph-level AUC: {val_auc:.4f} | ACC@0.5: {val_acc:.4f}\")\n",
        "\n",
        "# Kaggle submission (probabilities required)\n",
        "sub = test_para.rename(columns={\"prob\":\"y_prob\"})\n",
        "sub.to_csv(OUT_DIR / \"submission.csv\", index=False)\n",
        "print(\"Saved submission ->\", OUT_DIR / \"submission.csv\")\n",
        "sub.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h8LcZTWPDn9u",
        "outputId": "e6c70401-8629-4150-d5d2-2af3bd5f4843"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train tensors: (16322, 100, 768) Pos: 8161 Neg: 8161\n",
            "Val paragraphs: 20 Test paragraphs: 180\n",
            "\n",
            "===== Fold 1 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | loss 0.4956 | val AUC 0.9333 | ACC 0.8511\n",
            "Epoch 02 | loss 0.3403 | val AUC 0.9537 | ACC 0.8646\n",
            "Epoch 03 | loss 0.2954 | val AUC 0.9555 | ACC 0.8830\n",
            "Epoch 04 | loss 0.2752 | val AUC 0.9643 | ACC 0.8900\n",
            "Epoch 05 | loss 0.2633 | val AUC 0.9620 | ACC 0.8891\n",
            "Epoch 06 | loss 0.2498 | val AUC 0.9661 | ACC 0.8974\n",
            "Epoch 07 | loss 0.2418 | val AUC 0.9669 | ACC 0.9008\n",
            "Epoch 08 | loss 0.2348 | val AUC 0.9667 | ACC 0.8998\n",
            "Saved: /content/drive/MyDrive/colab_outputs/transformer_fold1.pt\n",
            "\n",
            "===== Fold 2 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | loss 0.5269 | val AUC 0.9246 | ACC 0.8371\n",
            "Epoch 02 | loss 0.3386 | val AUC 0.9502 | ACC 0.8711\n",
            "Epoch 03 | loss 0.2897 | val AUC 0.9546 | ACC 0.8784\n",
            "Epoch 04 | loss 0.2667 | val AUC 0.9569 | ACC 0.8882\n",
            "Epoch 05 | loss 0.2621 | val AUC 0.9611 | ACC 0.8897\n",
            "Epoch 06 | loss 0.2448 | val AUC 0.9625 | ACC 0.8922\n",
            "Epoch 07 | loss 0.2367 | val AUC 0.9628 | ACC 0.8946\n",
            "Epoch 08 | loss 0.2323 | val AUC 0.9627 | ACC 0.8943\n",
            "Saved: /content/drive/MyDrive/colab_outputs/transformer_fold2.pt\n",
            "\n",
            "===== Fold 3 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | loss 0.5078 | val AUC 0.9197 | ACC 0.8404\n",
            "Epoch 02 | loss 0.3311 | val AUC 0.9532 | ACC 0.8778\n",
            "Epoch 03 | loss 0.2844 | val AUC 0.9570 | ACC 0.8768\n",
            "Epoch 04 | loss 0.2683 | val AUC 0.9592 | ACC 0.8928\n",
            "Epoch 05 | loss 0.2572 | val AUC 0.9612 | ACC 0.8934\n",
            "Epoch 06 | loss 0.2444 | val AUC 0.9618 | ACC 0.8937\n",
            "Epoch 07 | loss 0.2337 | val AUC 0.9620 | ACC 0.8934\n",
            "Epoch 08 | loss 0.2290 | val AUC 0.9625 | ACC 0.8931\n",
            "Saved: /content/drive/MyDrive/colab_outputs/transformer_fold3.pt\n",
            "\n",
            "===== Fold 4 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | loss 0.5075 | val AUC 0.9316 | ACC 0.8116\n",
            "Epoch 02 | loss 0.3323 | val AUC 0.9491 | ACC 0.8750\n",
            "Epoch 03 | loss 0.2839 | val AUC 0.9582 | ACC 0.8903\n",
            "Epoch 04 | loss 0.2756 | val AUC 0.9587 | ACC 0.8857\n",
            "Epoch 05 | loss 0.2539 | val AUC 0.9599 | ACC 0.8885\n",
            "Epoch 06 | loss 0.2458 | val AUC 0.9615 | ACC 0.8955\n",
            "Epoch 07 | loss 0.2352 | val AUC 0.9615 | ACC 0.8925\n",
            "Epoch 08 | loss 0.2312 | val AUC 0.9618 | ACC 0.8937\n",
            "Saved: /content/drive/MyDrive/colab_outputs/transformer_fold4.pt\n",
            "\n",
            "===== Fold 5 / 5 =====\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | loss 0.5189 | val AUC 0.9244 | ACC 0.8002\n",
            "Epoch 02 | loss 0.3346 | val AUC 0.9569 | ACC 0.8719\n",
            "Epoch 03 | loss 0.2922 | val AUC 0.9604 | ACC 0.8961\n",
            "Epoch 04 | loss 0.2775 | val AUC 0.9576 | ACC 0.8869\n",
            "Epoch 05 | loss 0.2602 | val AUC 0.9641 | ACC 0.8989\n",
            "Epoch 06 | loss 0.2442 | val AUC 0.9637 | ACC 0.8971\n",
            "Epoch 07 | loss 0.2381 | val AUC 0.9651 | ACC 0.9007\n",
            "Epoch 08 | loss 0.2332 | val AUC 0.9654 | ACC 0.9026\n",
            "Saved: /content/drive/MyDrive/colab_outputs/transformer_fold5.pt\n",
            "\n",
            "OOF AUC: 0.9634 | OOF ACC@0.5: 0.8967\n",
            "Validation paragraph-level AUC: 0.9200 | ACC@0.5: 0.8000\n",
            "Saved submission -> /content/drive/MyDrive/colab_outputs/submission.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id    y_prob\n",
              "0  15  0.071721\n",
              "1  16  0.162859\n",
              "2  17  0.056796\n",
              "3  18  0.439647\n",
              "4  19  0.189955"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-12a7ebd0-e6ab-4b36-8af9-d5aefa2a890e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>y_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>15</td>\n",
              "      <td>0.071721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>16</td>\n",
              "      <td>0.162859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>17</td>\n",
              "      <td>0.056796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18</td>\n",
              "      <td>0.439647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19</td>\n",
              "      <td>0.189955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-12a7ebd0-e6ab-4b36-8af9-d5aefa2a890e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-12a7ebd0-e6ab-4b36-8af9-d5aefa2a890e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-12a7ebd0-e6ab-4b36-8af9-d5aefa2a890e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7aefc622-87f6-4b34-a415-330e66932f71\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7aefc622-87f6-4b34-a415-330e66932f71')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7aefc622-87f6-4b34-a415-330e66932f71 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "sub",
              "summary": "{\n  \"name\": \"sub\",\n  \"rows\": 180,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 52,\n        \"min\": 15,\n        \"max\": 199,\n        \"num_unique_values\": 180,\n        \"samples\": [\n          39,\n          62,\n          173\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_prob\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 180,\n        \"samples\": [\n          0.4419862926006317,\n          0.4763040542602539,\n          0.20216092467308044\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}