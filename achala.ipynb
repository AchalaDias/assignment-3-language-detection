{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b56828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # AI vs Human Text Classifier — Baseline (Part 1)\n",
    "# - Mean pooling over sentence embeddings (100x768) → paragraph vector (768)\n",
    "# - StandardScaler + Logistic Regression (Calibrated)\n",
    "# - 5-fold CV, OOF metrics, threshold tuning\n",
    "# - Save artefacts, run test inference, write submission.csv\n",
    "\n",
    "# %%\n",
    "import os, json, math, gc, random, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import joblib\n",
    "from tqdm.auto import tqdm\n",
    "np.set_printoptions(suppress=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f4bcfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ==== CONFIG ====\n",
    "DATA_DIR = Path(\"./data\")  # put your files here\n",
    "TRAIN_AI_PATH = DATA_DIR / \"train/train_ai.npy\"\n",
    "TRAIN_HUMAN_PATH = DATA_DIR / \"train/train_human.npy\"\n",
    "VAL_JSONL = DATA_DIR / \"train/validation.jsonl\"       # optional sanity set\n",
    "TEST_JSONL = DATA_DIR / \"test/test_features.jsonl\"   # required for submission\n",
    "\n",
    "MODELS_DIR = Path(\"./models\")\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "N_FOLDS = 5\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "SUBMISSION_PATH = Path(\"./submission.csv\")\n",
    "ART_SCALER = MODELS_DIR / \"scaler.pkl\"\n",
    "ART_MODEL = MODELS_DIR / \"logreg_calibrated.pkl\"\n",
    "ART_CONFIG = MODELS_DIR / \"config.json\"\n",
    "ART_THRESHOLD = MODELS_DIR / \"final_threshold.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd91992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def load_train(train_ai_path, train_human_path):\n",
    "    X_ai = np.load(train_ai_path)      # (n_ai, 100, 768)\n",
    "    X_h  = np.load(train_human_path)   # (n_h, 100, 768)\n",
    "    y = np.array([1]*len(X_ai) + [0]*len(X_h), dtype=np.int64)\n",
    "    X = np.concatenate([X_ai, X_h], axis=0)     # (n, 100, 768)\n",
    "    return X, y\n",
    "\n",
    "def read_jsonl(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            yield json.loads(line)\n",
    "\n",
    "def load_jsonl_features(path):\n",
    "    \"\"\"Returns: list of dicts with keys: id, features(np.array of shape (<=100,768))\"\"\"\n",
    "    items = []\n",
    "    for obj in read_jsonl(path):\n",
    "        # Expect at least {\"id\": ..., \"features\": [[...],[...],...]}\n",
    "        pid = obj.get(\"id\")\n",
    "        feats = np.asarray(obj.get(\"features\"), dtype=np.float32)\n",
    "        # Ensure 2D (n_sent, 768)\n",
    "        if feats.ndim == 1:\n",
    "            feats = feats.reshape(1, -1)\n",
    "        items.append({\"id\": pid, \"features\": feats})\n",
    "    return items\n",
    "\n",
    "def sentence_mask(x, eps=1e-8):\n",
    "    \"\"\"\n",
    "    Works for (..., 768) – returns mask of shape (...,)\n",
    "    True where the 768-d vector is non-zero.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    norms = np.linalg.norm(x, axis=-1)\n",
    "    return (norms > eps)\n",
    "\n",
    "def mean_pool(x):\n",
    "    \"\"\"\n",
    "    Robust mean pooling:\n",
    "    - Accepts (100,768)\n",
    "    - Accepts (segments, 100, 768)\n",
    "    - Flattens all leading dims into a single sequence of 768-d vectors,\n",
    "      masks near-zero rows, and averages.\n",
    "    Returns: (768,)\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    if x.ndim < 2:\n",
    "        # Unexpected shape – return zeros\n",
    "        return np.zeros((768,), dtype=np.float32)\n",
    "\n",
    "    # Ensure last dim is feature dim\n",
    "    feat_dim = x.shape[-1]\n",
    "    if feat_dim != 768:\n",
    "        raise ValueError(f\"Expected last dim = 768, got {feat_dim} with shape {x.shape}\")\n",
    "\n",
    "    # Flatten all but last dim to get (N, 768), where N = product of leading dims\n",
    "    x_flat = x.reshape(-1, feat_dim)  # (N, 768)\n",
    "\n",
    "    m = sentence_mask(x_flat).astype(np.float32)  # (N,)\n",
    "    count = m.sum()\n",
    "    if count < 1:\n",
    "        return np.zeros((feat_dim,), dtype=np.float32)\n",
    "\n",
    "    return (x_flat * m[:, None]).sum(axis=0) / count\n",
    "\n",
    "def to_paragraph_matrix_from_npy_block(X):\n",
    "    \"\"\"X: (n, 100, 768) -> (n, 768) pooled\"\"\"\n",
    "    pooled = np.zeros((X.shape[0], X.shape[2]), dtype=np.float32)\n",
    "    for i in range(X.shape[0]):\n",
    "        pooled[i] = mean_pool(X[i])\n",
    "    return pooled\n",
    "\n",
    "def to_paragraph_matrix_from_jsonl_items(items):\n",
    "    \"\"\"items: list of dict with features (shape (100,768) or (S,100,768)) -> DataFrame(id, vector)\"\"\"\n",
    "    rows = []\n",
    "    for obj in items:\n",
    "        pid = obj[\"id\"]\n",
    "        vec = mean_pool(obj[\"features\"])\n",
    "        rows.append({\"id\": pid, \"vector\": vec})\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4c70983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train raw shape: (16322, 100, 768) Labels: (16322,) Pos rate: 0.5\n",
      "Pooled train shape: (16322, 768)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "X_raw, y = load_train(TRAIN_AI_PATH, TRAIN_HUMAN_PATH)\n",
    "print(\"Train raw shape:\", X_raw.shape, \"Labels:\", y.shape, \"Pos rate:\", y.mean())\n",
    "\n",
    "X = to_paragraph_matrix_from_npy_block(X_raw)   # (n, 768)\n",
    "print(\"Pooled train shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5b0886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 1] AUC=0.9686 F1=0.9085 Acc=0.9066 Prec=0.8906 Rec=0.9271 Thr=0.465\n",
      "[Fold 2] AUC=0.9658 F1=0.9033 Acc=0.9029 Prec=0.8992 Rec=0.9075 Thr=0.485\n",
      "[Fold 3] AUC=0.9649 F1=0.9045 Acc=0.9020 Prec=0.8814 Rec=0.9289 Thr=0.475\n",
      "[Fold 4] AUC=0.9644 F1=0.9033 Acc=0.9017 Prec=0.8881 Rec=0.9191 Thr=0.416\n",
      "[Fold 5] AUC=0.9679 F1=0.9057 Acc=0.9035 Prec=0.8853 Rec=0.9271 Thr=0.455\n",
      "\n",
      "=== OOF Summary ===\n",
      "OOF_AUC: 0.9660641019648668\n",
      "OOF_F1: 0.9043258223882396\n",
      "OOF_Acc: 0.9027080014704081\n",
      "OOF_Prec: 0.8895341946189403\n",
      "OOF_Rec: 0.9196176939100601\n",
      "final_thr: 0.46535353535353535\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "      <th>Prec</th>\n",
       "      <th>Rec</th>\n",
       "      <th>thr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.968649</td>\n",
       "      <td>0.908491</td>\n",
       "      <td>0.906585</td>\n",
       "      <td>0.890588</td>\n",
       "      <td>0.927128</td>\n",
       "      <td>0.465354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.965775</td>\n",
       "      <td>0.903324</td>\n",
       "      <td>0.902910</td>\n",
       "      <td>0.899211</td>\n",
       "      <td>0.907475</td>\n",
       "      <td>0.485152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.964851</td>\n",
       "      <td>0.904535</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.881395</td>\n",
       "      <td>0.928922</td>\n",
       "      <td>0.475253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.964383</td>\n",
       "      <td>0.903342</td>\n",
       "      <td>0.901654</td>\n",
       "      <td>0.888099</td>\n",
       "      <td>0.919118</td>\n",
       "      <td>0.415859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.967931</td>\n",
       "      <td>0.905717</td>\n",
       "      <td>0.903493</td>\n",
       "      <td>0.885313</td>\n",
       "      <td>0.927083</td>\n",
       "      <td>0.455455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold       AUC        F1       Acc      Prec       Rec       thr\n",
       "0     1  0.968649  0.908491  0.906585  0.890588  0.927128  0.465354\n",
       "1     2  0.965775  0.903324  0.902910  0.899211  0.907475  0.485152\n",
       "2     3  0.964851  0.904535  0.901961  0.881395  0.928922  0.475253\n",
       "3     4  0.964383  0.903342  0.901654  0.888099  0.919118  0.415859\n",
       "4     5  0.967931  0.905717  0.903493  0.885313  0.927083  0.455455"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "from sklearn.base import clone\n",
    "\n",
    "def fit_oof_cv(X, y, n_folds=5, seed=42):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    oof_pred = np.zeros(len(y), dtype=np.float32)\n",
    "    oof_thr_list, fold_metrics = [], []\n",
    "    C_grid = [0.5, 1.0, 2.0]\n",
    "\n",
    "    for fold, (trn_idx, val_idx) in enumerate(skf.split(X, y), 1):\n",
    "        X_tr, X_va = X[trn_idx], X[val_idx]\n",
    "        y_tr, y_va = y[trn_idx], y[val_idx]\n",
    "\n",
    "        best_auc, best_model = -1, None\n",
    "        for C in C_grid:\n",
    "            base = Pipeline([\n",
    "                (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "                (\"clf\", LogisticRegression(\n",
    "                    penalty=\"l2\", solver=\"saga\", max_iter=4000, C=C, n_jobs=-1, random_state=seed))\n",
    "            ])\n",
    "            cal = CalibratedClassifierCV(estimator=base, method=\"isotonic\", cv=3)\n",
    "            cal.fit(X_tr, y_tr)\n",
    "            p_va = cal.predict_proba(X_va)[:, 1]\n",
    "            auc = roc_auc_score(y_va, p_va)\n",
    "            if auc > best_auc:\n",
    "                best_auc, best_model, best_p_va = auc, cal, p_va\n",
    "\n",
    "        p_va = best_p_va\n",
    "        oof_pred[val_idx] = p_va\n",
    "\n",
    "        # F1-optimal threshold\n",
    "        best_thr, best_f1 = 0.5, -1\n",
    "        for t in np.linspace(0.01, 0.99, 199):\n",
    "            f1 = f1_score(y_va, (p_va >= t).astype(int))\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_thr = f1, t\n",
    "\n",
    "        pred_lbl = (p_va >= best_thr).astype(int)\n",
    "        auc = roc_auc_score(y_va, p_va)\n",
    "        acc = accuracy_score(y_va, pred_lbl)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(y_va, pred_lbl, average=\"binary\", zero_division=0)\n",
    "        fold_metrics.append({\"fold\": fold, \"AUC\": auc, \"F1\": f1, \"Acc\": acc, \"Prec\": prec, \"Rec\": rec, \"thr\": best_thr})\n",
    "        oof_thr_list.append(best_thr)\n",
    "        print(f\"[Fold {fold}] AUC={auc:.4f} F1={f1:.4f} Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} Thr={best_thr:.3f}\")\n",
    "\n",
    "    oof_auc = roc_auc_score(y, oof_pred)\n",
    "    final_thr = float(np.median(oof_thr_list))\n",
    "    pred_lbl = (oof_pred >= final_thr).astype(int)\n",
    "    oof_acc = accuracy_score(y, pred_lbl)\n",
    "    oof_prec, oof_rec, oof_f1, _ = precision_recall_fscore_support(y, pred_lbl, average=\"binary\", zero_division=0)\n",
    "    summary = {\"OOF_AUC\": oof_auc, \"OOF_F1\": oof_f1, \"OOF_Acc\": oof_acc, \"OOF_Prec\": oof_prec, \"OOF_Rec\": oof_rec,\n",
    "               \"final_thr\": final_thr, \"folds\": fold_metrics}\n",
    "    return oof_pred, summary\n",
    "\n",
    "\n",
    "oof_pred, summary = fit_oof_cv(X, y, n_folds=N_FOLDS, seed=SEED)\n",
    "print(\"\\n=== OOF Summary ===\")\n",
    "for k, v in summary.items():\n",
    "    if k != \"folds\":\n",
    "        print(f\"{k}: {v}\")\n",
    "pd.DataFrame(summary[\"folds\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc5910c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m final_model\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 2) Choose threshold\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#    Start from OOF-derived median threshold, then (optionally) nudge down a bit to trade precision for recall.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m thr_oof \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(summary[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_thr\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     16\u001b[0m thr_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0.0\u001b[39m, thr_oof \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m0.05\u001b[39m)  \u001b[38;5;66;03m# small nudge; adjust if needed\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== OOF-based threshold ==\u001b[39m\u001b[38;5;124m\"\u001b[39m, thr_oof)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": [
    "# === Final fit (LogReg + isotonic calibration), threshold selection, and artefact saving ===\n",
    "\n",
    "# 1) Fit calibrated final model on ALL training data\n",
    "best_C = 1.0  # keep or pick from your CV sweep\n",
    "final_base = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        penalty=\"l2\", solver=\"saga\", max_iter=4000, C=best_C, n_jobs=-1, random_state=SEED))\n",
    "])\n",
    "final_model = CalibratedClassifierCV(estimator=final_base, method=\"isotonic\", cv=5)\n",
    "final_model.fit(X, y)\n",
    "\n",
    "# 2) Choose threshold\n",
    "#    Start from OOF-derived median threshold, then (optionally) nudge down a bit to trade precision for recall.\n",
    "thr_oof = float(summary[\"final_thr\"])\n",
    "thr_val = max(0.0, thr_oof - 0.05)  # small nudge; adjust if needed\n",
    "\n",
    "print(\"== OOF-based threshold ==\", thr_oof)\n",
    "_ = evaluate_on_validation(VAL_JSONL, final_model, thr_oof)\n",
    "\n",
    "print(\"== Val-nudged threshold ==\", thr_val)\n",
    "_ = evaluate_on_validation(VAL_JSONL, final_model, thr_val)\n",
    "\n",
    "# Pick which threshold you want to use going forward:\n",
    "chosen_threshold = thr_val   # or use thr_oof if you prefer higher precision\n",
    "\n",
    "# 3) Save artefacts\n",
    "joblib.dump(final_model, ART_MODEL)\n",
    "\n",
    "config = {\n",
    "    \"seed\": SEED,\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"clf\": \"LogReg(saga)+Calibrated(isotonic)\",\n",
    "    \"C\": best_C,\n",
    "    \"vector\": \"mean_pool_768\",\n",
    "    \"final_threshold_oof\": thr_oof,\n",
    "    \"final_threshold_chosen\": chosen_threshold\n",
    "}\n",
    "json.dump(config, open(ART_CONFIG, \"w\"))\n",
    "\n",
    "with open(ART_THRESHOLD, \"w\") as f:\n",
    "    f.write(str(chosen_threshold))\n",
    "\n",
    "print(\"Saved:\", ART_MODEL, ART_CONFIG, ART_THRESHOLD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f4b2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c0ebe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Validation] AUC=0.9900 F1=0.6667 Acc=0.7500 Prec=1.0000 Rec=0.5000\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def evaluate_on_validation(val_jsonl_path, model, threshold):\n",
    "    if not Path(val_jsonl_path).exists():\n",
    "        print(\"No validation file found. Skipping.\")\n",
    "        return None\n",
    "    items = load_jsonl_features(val_jsonl_path)\n",
    "    dfv = to_paragraph_matrix_from_jsonl_items(items)\n",
    "    # Expect labels exist in validation.jsonl; if not, skip\n",
    "    # Common schema: {\"id\":..., \"features\":[...], \"label\": 0/1}\n",
    "    labels = []\n",
    "    for obj in read_jsonl(val_jsonl_path):\n",
    "        labels.append(int(obj.get(\"label\", 0)))\n",
    "    yv = np.array(labels, dtype=np.int64)\n",
    "\n",
    "    Xv = np.stack(dfv[\"vector\"].values)  # (n, 768)\n",
    "    pv = model.predict_proba(Xv)[:, 1]\n",
    "    auc = roc_auc_score(yv, pv)\n",
    "    yhat = (pv >= threshold).astype(int)\n",
    "    acc = accuracy_score(yv, yhat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(yv, yhat, average=\"binary\", zero_division=0)\n",
    "    print(f\"[Validation] AUC={auc:.4f} F1={f1:.4f} Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f}\")\n",
    "    return {\"AUC\":auc, \"F1\":f1, \"Acc\":acc, \"Prec\":prec, \"Rec\":rec}\n",
    "\n",
    "_ = evaluate_on_validation(VAL_JSONL, final_model, summary[\"final_thr\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75cbcfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote submission to: submission_base_prob.csv\n"
     ]
    }
   ],
   "source": [
    "# === Kaggle-compliant: id,y_prob (no thresholding) ===\n",
    "def predict_test_and_write_submission_prob(test_jsonl_path, model, out_csv_path):\n",
    "    items = load_jsonl_features(test_jsonl_path)\n",
    "    dft = to_paragraph_matrix_from_jsonl_items(items)\n",
    "    Xt = np.stack(dft[\"vector\"].values)\n",
    "    y_prob = model.predict_proba(Xt)[:, 1]          # <-- probability of class 1\n",
    "    sub = pd.DataFrame({\"id\": dft[\"id\"], \"y_prob\": y_prob})\n",
    "    sub.to_csv(out_csv_path, index=False)\n",
    "    print(\"Wrote submission to:\", out_csv_path)\n",
    "    return sub\n",
    "\n",
    "# write the baseline prob file (good quick uplift)\n",
    "SUBMISSION_BASE_PROB = Path(\"./submission_base_prob.csv\")\n",
    "_ = predict_test_and_write_submission_prob(TEST_JSONL, final_model, SUBMISSION_BASE_PROB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b6514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3bce17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1f4dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e3dc630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Part 2 — Lightweight Transformer + Attention Pooling (PyTorch)\n",
    "\n",
    "# %%\n",
    "import os, json, math, gc, random, time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264d53e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Reuse DATA_DIR, MODELS_DIR, VAL_JSONL, TEST_JSONL, SEED, etc. from Part 1\n",
    "# If not defined above, uncomment and set them here:\n",
    "# DATA_DIR = Path(\"./data\")\n",
    "# MODELS_DIR = Path(\"./models\")\n",
    "# VAL_JSONL = DATA_DIR / \"validation.jsonl\"\n",
    "# TEST_JSONL = DATA_DIR / \"test_features.jsonl\"\n",
    "# SEED = 42\n",
    "# N_FOLDS = 5\n",
    "\n",
    "TRANS_DIR = MODELS_DIR / \"transformer_v1\"\n",
    "TRANS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CFG = {\n",
    "    \"max_len\": 100,           # fixed number of sentences per item\n",
    "    \"feat_dim\": 768,          # embedding size\n",
    "    \"d_model\": 256,           # transformer hidden size\n",
    "    \"n_heads\": 4,\n",
    "    \"n_layers\": 2,\n",
    "    \"dropout\": 0.1,\n",
    "    \"batch_size\": 32,\n",
    "    \"lr\": 3e-4,\n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"epochs\": 20,\n",
    "    \"early_stop_patience\": 5,\n",
    "    \"amp\": True,              # mixed precision if CUDA\n",
    "    \"seed\": SEED\n",
    "}\n",
    "json.dump(CFG, open(TRANS_DIR / \"config.json\", \"w\"))\n",
    "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf5165b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def pad_or_truncate(x: np.ndarray, max_len=100):\n",
    "    \"\"\"\n",
    "    x: (n_sent, 768) or (100,768). Returns (max_len, 768) padded with zeros or truncated.\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=np.float32)\n",
    "    if x.ndim == 3:\n",
    "        # If given (segments, 100, 768), flatten to (segments*100, 768) first\n",
    "        x = x.reshape(-1, x.shape[-1])\n",
    "    n = x.shape[0]\n",
    "    if n == max_len:\n",
    "        return x\n",
    "    if n > max_len:\n",
    "        return x[:max_len]\n",
    "    # pad\n",
    "    out = np.zeros((max_len, x.shape[1]), dtype=np.float32)\n",
    "    out[:n] = x\n",
    "    return out\n",
    "\n",
    "def make_mask(x: np.ndarray):\n",
    "    \"\"\"\n",
    "    x: (max_len, 768). Mask True where row is non-zero.\n",
    "    \"\"\"\n",
    "    return (np.linalg.norm(x, axis=-1) > 1e-8).astype(np.bool_)\n",
    "\n",
    "class ParagraphDataset(Dataset):\n",
    "    def __init__(self, X, y=None, max_len=100):\n",
    "        \"\"\"\n",
    "        X:\n",
    "          - if training from npy: shape (N, 100, 768)\n",
    "          - if from jsonl items: list of dicts {id, features}\n",
    "        y: labels or None\n",
    "        \"\"\"\n",
    "        self.max_len = max_len\n",
    "        self.ids = None\n",
    "\n",
    "        if isinstance(X, np.ndarray):\n",
    "            self.X = X  # (N, 100, 768)\n",
    "            self.ids = np.arange(len(X))\n",
    "        elif isinstance(X, list):  # jsonl items\n",
    "            self.ids = [obj[\"id\"] for obj in X]\n",
    "            mats, masks = [], []\n",
    "            for obj in X:\n",
    "                mat = pad_or_truncate(np.asarray(obj[\"features\"], dtype=np.float32), max_len=self.max_len)\n",
    "                mats.append(mat)\n",
    "                masks.append(make_mask(mat))\n",
    "            self.X = np.stack(mats)   # (N, max_len, 768)\n",
    "            self._masks = np.stack(masks)  # (N, max_len)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported X type.\")\n",
    "\n",
    "        self.y = None if y is None else np.asarray(y, dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {\n",
    "            \"x\": torch.from_numpy(self.X[idx]),                    # (max_len, 768)\n",
    "            \"mask\": torch.from_numpy(make_mask(self.X[idx])) if not hasattr(self, \"_masks\") else torch.from_numpy(self._masks[idx])  # (max_len,)\n",
    "        }\n",
    "        if self.y is not None:\n",
    "            item[\"y\"] = torch.tensor(self.y[idx], dtype=torch.long)\n",
    "        if self.ids is not None:\n",
    "            item[\"id\"] = self.ids[idx]\n",
    "        return item\n",
    "\n",
    "def make_loader(dataset, batch_size, shuffle=False, num_workers=0, pin_memory=None):\n",
    "    \"\"\"\n",
    "    Use num_workers=0 in notebooks (esp. on macOS) to avoid:\n",
    "    AttributeError: Can't get attribute 'ParagraphDataset' on <module '__main__'>\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    if pin_memory is None:\n",
    "        pin_memory = (torch.cuda.is_available() and torch.device(\"cuda\").type == \"cuda\")\n",
    "    return DataLoader(dataset,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=shuffle,\n",
    "                      num_workers=0,          # <— force single-process workers\n",
    "                      pin_memory=pin_memory,\n",
    "                      drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc6ffa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=100):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)  # (max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, d_model)\n",
    "        T = x.size(1)\n",
    "        return x + self.pe[:T].unsqueeze(0)\n",
    "\n",
    "class AttnPool(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # x: (B,T,d), mask: (B,T) [True for valid]\n",
    "        attn_logits = self.attn(x).squeeze(-1)                  # (B,T)\n",
    "        attn_logits = attn_logits.masked_fill(~mask, -1e9)\n",
    "        w = F.softmax(attn_logits, dim=-1).unsqueeze(-1)        # (B,T,1)\n",
    "        pooled = (x * w).sum(dim=1)                             # (B,d)\n",
    "        return pooled\n",
    "\n",
    "class LightTransformer(nn.Module):\n",
    "    def __init__(self, feat_dim=768, d_model=256, n_heads=4, n_layers=2, dropout=0.1, max_len=100):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(feat_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, dim_feedforward=d_model*4,\n",
    "                                                   dropout=dropout, batch_first=True, activation=\"gelu\")\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "        self.posenc = PositionalEncoding(d_model, max_len=max_len)\n",
    "        self.pool = AttnPool(d_model)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(d_model),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        x: (B,T,768), mask: (B,T) bool\n",
    "        \"\"\"\n",
    "        h = self.proj(x)                  # (B,T,d)\n",
    "        h = self.posenc(h)\n",
    "        # Transformer expects mask where True=positions to ignore\n",
    "        src_key_padding_mask = ~mask      # (B,T)\n",
    "        h = self.encoder(h, src_key_padding_mask=src_key_padding_mask)\n",
    "        pooled = self.pool(h, mask)       # (B,d)\n",
    "        logits = self.head(pooled).squeeze(-1)  # (B,)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "726b8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def train_one_epoch(model, loader, optim, scaler, device):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    for batch in loader:\n",
    "        x = batch[\"x\"].to(device).float()\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "        y = batch[\"y\"].to(device).float()\n",
    "\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "        if scaler is not None:\n",
    "            with torch.cuda.amp.autocast():\n",
    "                logits = model(x, mask)\n",
    "                loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optim)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            logits = model(x, mask)\n",
    "            loss = F.binary_cross_entropy_with_logits(logits, y)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        total += loss.item() * x.size(0)\n",
    "    return total / len(loader.dataset)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_proba(model, loader, device):\n",
    "    model.eval()\n",
    "    probs = []\n",
    "    for batch in loader:\n",
    "        x = batch[\"x\"].to(device).float()\n",
    "        mask = batch[\"mask\"].to(device)\n",
    "        logits = model(x, mask)\n",
    "        p = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        probs.append(p)\n",
    "    return np.concatenate(probs, axis=0)\n",
    "\n",
    "def fit_cv_transformer(X_raw, y, cfg, n_folds=5, seed=42, out_dir=TRANS_DIR):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    best_thresholds, fold_paths = [], []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_raw, y), 1):\n",
    "        print(f\"\\n=== Fold {fold}/{n_folds} ===\")\n",
    "        tr_ds = ParagraphDataset(X_raw[tr_idx], y=y[tr_idx], max_len=cfg[\"max_len\"])\n",
    "        va_ds = ParagraphDataset(X_raw[va_idx], y=y[va_idx], max_len=cfg[\"max_len\"])\n",
    "        tr_loader = make_loader(tr_ds, cfg[\"batch_size\"], shuffle=True)\n",
    "        va_loader = make_loader(va_ds, cfg[\"batch_size\"], shuffle=False)\n",
    "\n",
    "        model = LightTransformer(\n",
    "            feat_dim=cfg[\"feat_dim\"], d_model=cfg[\"d_model\"], n_heads=cfg[\"n_heads\"],\n",
    "            n_layers=cfg[\"n_layers\"], dropout=cfg[\"dropout\"], max_len=cfg[\"max_len\"]\n",
    "        ).to(device)\n",
    "\n",
    "        optim = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=(cfg[\"amp\"] and device.type == \"cuda\"))\n",
    "\n",
    "        best_auc, best_state, no_improve = -1.0, None, 0\n",
    "        for epoch in range(1, cfg[\"epochs\"]+1):\n",
    "            tr_loss = train_one_epoch(model, tr_loader, optim, scaler, device)\n",
    "            # validation\n",
    "            va_probs = predict_proba(model, va_loader, device)\n",
    "            auc = roc_auc_score(y[va_idx], va_probs)\n",
    "            print(f\"Epoch {epoch:02d} | train_loss={tr_loss:.4f} | val_auc={auc:.5f}\")\n",
    "\n",
    "            if auc > best_auc + 1e-5:\n",
    "                best_auc = auc\n",
    "                best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                if no_improve >= cfg[\"early_stop_patience\"]:\n",
    "                    print(f\"Early stopping at epoch {epoch} (best AUC {best_auc:.5f})\")\n",
    "                    break\n",
    "\n",
    "        # restore best\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        # final fold validation probabilities\n",
    "        va_probs = predict_proba(model, va_loader, device)\n",
    "        oof[va_idx] = va_probs\n",
    "\n",
    "        # choose best threshold on this fold (F1)\n",
    "        best_thr, best_f1 = 0.5, -1.0\n",
    "        for t in np.linspace(0.01, 0.99, 199):\n",
    "            f1 = f1_score(y[va_idx], (va_probs >= t).astype(int))\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_thr = f1, t\n",
    "        best_thresholds.append(float(best_thr))\n",
    "\n",
    "        # save fold checkpoint\n",
    "        fold_path = out_dir / f\"fold{fold}.pt\"\n",
    "        torch.save({\"model_state\": best_state, \"cfg\": cfg}, fold_path)\n",
    "        fold_paths.append(str(fold_path))\n",
    "        del model, optim, scaler, tr_loader, va_loader\n",
    "        gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    # OOF summary\n",
    "    oof_auc = roc_auc_score(y, oof)\n",
    "    print(f\"\\nOOF AUC: {oof_auc:.5f}\")\n",
    "    final_thr = float(np.median(best_thresholds))\n",
    "    return oof, oof_auc, best_thresholds, final_thr, fold_paths\n",
    "\n",
    "import types\n",
    "def _patched_fit_cv_transformer(X_raw, y, cfg, n_folds=5, seed=42, out_dir=TRANS_DIR):\n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=seed)\n",
    "    oof = np.zeros(len(y), dtype=np.float32)\n",
    "    best_thresholds, fold_paths = [], []\n",
    "\n",
    "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_raw, y), 1):\n",
    "        print(f\"\\n=== Fold {fold}/{n_folds} ===\")\n",
    "        tr_ds = ParagraphDataset(X_raw[tr_idx], y=y[tr_idx], max_len=cfg[\"max_len\"])\n",
    "        va_ds = ParagraphDataset(X_raw[va_idx], y=y[va_idx], max_len=cfg[\"max_len\"])\n",
    "        tr_loader = make_loader(tr_ds, cfg[\"batch_size\"], shuffle=True, num_workers=0)\n",
    "        va_loader = make_loader(va_ds, cfg[\"batch_size\"], shuffle=False, num_workers=0)\n",
    "\n",
    "        model = LightTransformer(\n",
    "            feat_dim=cfg[\"feat_dim\"], d_model=cfg[\"d_model\"], n_heads=cfg[\"n_heads\"],\n",
    "            n_layers=cfg[\"n_layers\"], dropout=cfg[\"dropout\"], max_len=cfg[\"max_len\"]\n",
    "        ).to(device)\n",
    "\n",
    "        optim = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n",
    "        # Updated AMP scaler API\n",
    "        scaler = torch.amp.GradScaler(\"cuda\", enabled=(cfg[\"amp\"] and device.type == \"cuda\"))\n",
    "\n",
    "        best_auc, best_state, no_improve = -1.0, None, 0\n",
    "        for epoch in range(1, cfg[\"epochs\"]+1):\n",
    "            tr_loss = train_one_epoch(model, tr_loader, optim, scaler, device)\n",
    "            va_probs = predict_proba(model, va_loader, device)\n",
    "            auc = roc_auc_score(y[va_idx], va_probs)\n",
    "            print(f\"Epoch {epoch:02d} | train_loss={tr_loss:.4f} | val_auc={auc:.5f}\")\n",
    "\n",
    "            if auc > best_auc + 1e-5:\n",
    "                best_auc = auc\n",
    "                best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "                no_improve = 0\n",
    "            else:\n",
    "                no_improve += 1\n",
    "                if no_improve >= cfg[\"early_stop_patience\"]:\n",
    "                    print(f\"Early stopping at epoch {epoch} (best AUC {best_auc:.5f})\")\n",
    "                    break\n",
    "\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "        va_probs = predict_proba(model, va_loader, device)\n",
    "        oof[va_idx] = va_probs\n",
    "\n",
    "        # F1-optimal threshold on this fold\n",
    "        best_thr, best_f1 = 0.5, -1.0\n",
    "        for t in np.linspace(0.01, 0.99, 199):\n",
    "            f1 = f1_score(y[va_idx], (va_probs >= t).astype(int))\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_thr = f1, t\n",
    "        best_thresholds.append(float(best_thr))\n",
    "\n",
    "        fold_path = out_dir / f\"fold{fold}.pt\"\n",
    "        torch.save({\"model_state\": best_state, \"cfg\": cfg}, fold_path)\n",
    "        fold_paths.append(str(fold_path))\n",
    "\n",
    "        del model, optim, scaler, tr_loader, va_loader\n",
    "        gc.collect()\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    oof_auc = roc_auc_score(y, oof)\n",
    "    print(f\"\\nOOF AUC: {oof_auc:.5f}\")\n",
    "    final_thr = float(np.median(best_thresholds))\n",
    "    return oof, oof_auc, best_thresholds, final_thr, fold_paths\n",
    "\n",
    "# replace the original function reference so your next cell uses the patched one\n",
    "fit_cv_transformer = _patched_fit_cv_transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93f647a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.4150 | val_auc=0.94423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=0.3052 | val_auc=0.96196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=0.2782 | val_auc=0.95162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=0.2600 | val_auc=0.96495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=0.2618 | val_auc=0.96229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train_loss=0.2428 | val_auc=0.96720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train_loss=0.2334 | val_auc=0.96460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train_loss=0.2342 | val_auc=0.96114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train_loss=0.2175 | val_auc=0.96210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=0.2155 | val_auc=0.96316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train_loss=0.2147 | val_auc=0.96797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train_loss=0.2009 | val_auc=0.96664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train_loss=0.1927 | val_auc=0.96684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train_loss=0.1959 | val_auc=0.96321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train_loss=0.1872 | val_auc=0.96265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train_loss=0.1841 | val_auc=0.96504\n",
      "Early stopping at epoch 16 (best AUC 0.96797)\n",
      "\n",
      "=== Fold 2/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.4201 | val_auc=0.94703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=0.3068 | val_auc=0.95439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=0.2911 | val_auc=0.95886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=0.2734 | val_auc=0.96153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=0.2517 | val_auc=0.95317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train_loss=0.2450 | val_auc=0.96277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train_loss=0.2313 | val_auc=0.96469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train_loss=0.2265 | val_auc=0.96538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train_loss=0.2255 | val_auc=0.96449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=0.2107 | val_auc=0.96472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train_loss=0.2022 | val_auc=0.96481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train_loss=0.2004 | val_auc=0.96086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train_loss=0.1906 | val_auc=0.96495\n",
      "Early stopping at epoch 13 (best AUC 0.96538)\n",
      "\n",
      "=== Fold 3/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.4020 | val_auc=0.94827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=0.3091 | val_auc=0.95493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=0.2830 | val_auc=0.95808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=0.2599 | val_auc=0.96130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=0.2490 | val_auc=0.94852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train_loss=0.2351 | val_auc=0.96368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train_loss=0.2224 | val_auc=0.96334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train_loss=0.2213 | val_auc=0.96400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train_loss=0.2084 | val_auc=0.96214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=0.2015 | val_auc=0.96291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train_loss=0.1929 | val_auc=0.96350\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train_loss=0.1887 | val_auc=0.96215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train_loss=0.1867 | val_auc=0.96104\n",
      "Early stopping at epoch 13 (best AUC 0.96400)\n",
      "\n",
      "=== Fold 4/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.4232 | val_auc=0.93440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=0.3094 | val_auc=0.95429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=0.3113 | val_auc=0.95783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=0.2584 | val_auc=0.95740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=0.2756 | val_auc=0.95836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train_loss=0.2447 | val_auc=0.96253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train_loss=0.2340 | val_auc=0.95897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train_loss=0.2265 | val_auc=0.96236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train_loss=0.2193 | val_auc=0.96406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=0.2143 | val_auc=0.96122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train_loss=0.2075 | val_auc=0.96264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train_loss=0.1986 | val_auc=0.95914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train_loss=0.1878 | val_auc=0.96002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train_loss=0.1783 | val_auc=0.96344\n",
      "Early stopping at epoch 14 (best AUC 0.96406)\n",
      "\n",
      "=== Fold 5/5 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.4174 | val_auc=0.94363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | train_loss=0.3107 | val_auc=0.95593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | train_loss=0.2832 | val_auc=0.96335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | train_loss=0.2701 | val_auc=0.95562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | train_loss=0.2446 | val_auc=0.96526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | train_loss=0.2472 | val_auc=0.96526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 | train_loss=0.2319 | val_auc=0.96551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 | train_loss=0.2302 | val_auc=0.96379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 | train_loss=0.2237 | val_auc=0.96591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | train_loss=0.2139 | val_auc=0.96372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | train_loss=0.2111 | val_auc=0.95510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | train_loss=0.2053 | val_auc=0.96388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | train_loss=0.2113 | val_auc=0.96615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | train_loss=0.1975 | val_auc=0.96393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | train_loss=0.1903 | val_auc=0.96456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | train_loss=0.1879 | val_auc=0.96357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | train_loss=0.1784 | val_auc=0.95766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kc/vdrqlr9x1rj06rkrzxt34zzw0000gn/T/ipykernel_52386/3264508150.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/opt/anaconda3/lib/python3.11/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | train_loss=0.1739 | val_auc=0.95736\n",
      "Early stopping at epoch 18 (best AUC 0.96615)\n",
      "\n",
      "OOF AUC: 0.95645\n",
      "Fold thresholds (F1-optimal): [0.495, 0.094, 0.525, 0.356, 0.495]\n",
      "Final threshold (median): 0.4951\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# X_raw, y already loaded in Part 1 (np.load + concat). If not, reload them here.\n",
    "# X_raw: (N, 100, 768), y: (N,)\n",
    "oof_probs_nn, oof_auc_nn, fold_thrs_nn, final_thr_nn, fold_paths = fit_cv_transformer(\n",
    "    X_raw, y, CFG, n_folds=N_FOLDS, seed=SEED, out_dir=TRANS_DIR\n",
    ")\n",
    "print(\"Fold thresholds (F1-optimal):\", [round(t, 3) for t in fold_thrs_nn])\n",
    "print(\"Final threshold (median):\", round(final_thr_nn, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6aaad547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class FoldEnsembleAdapter:\n",
    "    \"\"\"\n",
    "    Provides predict_proba(X) like a scikit model.\n",
    "    X must be (N, 768) **if using mean-pooling**; BUT we want (N, 100, 768).\n",
    "    So for this adapter, we'll expect raw matrices and do the padding here.\n",
    "    To integrate with your existing evaluate_on_validation/predict_test...,\n",
    "    we add small wrappers below.\n",
    "    \"\"\"\n",
    "    def __init__(self, fold_paths, cfg, device):\n",
    "        self.fold_paths = fold_paths\n",
    "        self.cfg = cfg\n",
    "        self.device = device\n",
    "        self.models = []\n",
    "        self._load_models()\n",
    "\n",
    "    def _load_models(self):\n",
    "        self.models = []\n",
    "        for p in self.fold_paths:\n",
    "            ckpt = torch.load(p, map_location=\"cpu\")\n",
    "            m = LightTransformer(\n",
    "                feat_dim=self.cfg[\"feat_dim\"], d_model=self.cfg[\"d_model\"],\n",
    "                n_heads=self.cfg[\"n_heads\"], n_layers=self.cfg[\"n_layers\"],\n",
    "                dropout=self.cfg[\"dropout\"], max_len=self.cfg[\"max_len\"]\n",
    "            ).to(self.device)\n",
    "            m.load_state_dict(ckpt[\"model_state\"])\n",
    "            m.eval()\n",
    "            self.models.append(m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _predict_loader(self, loader):\n",
    "        probs_fold = []\n",
    "        for m in self.models:\n",
    "            p = predict_proba(m, loader, self.device)\n",
    "            probs_fold.append(p)\n",
    "        probs = np.mean(np.stack(probs_fold, axis=0), axis=0)\n",
    "        return probs\n",
    "\n",
    "    # Convenience to mimic scikit's predict_proba for (N,768) inputs\n",
    "    # We'll override with wrappers below that build proper datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80438cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def evaluate_validation_with_nn(val_jsonl_path, adapter, threshold):\n",
    "    if not Path(val_jsonl_path).exists():\n",
    "        print(\"No validation file found. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    # Load JSONL items (reuse your function from Part 1)\n",
    "    items = load_jsonl_features(val_jsonl_path)\n",
    "\n",
    "    # Build dataset/loader for the NN (pads to max_len)\n",
    "    val_ds = ParagraphDataset(items, y=None, max_len=CFG[\"max_len\"])\n",
    "    val_loader = make_loader(val_ds, CFG[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    # Collect labels from jsonl\n",
    "    labels = [int(obj.get(\"label\", 0)) for obj in read_jsonl(val_jsonl_path)]\n",
    "    yv = np.array(labels, dtype=np.int64)\n",
    "\n",
    "    # Predict (averaging folds)\n",
    "    pv = adapter._predict_loader(val_loader)\n",
    "    auc = roc_auc_score(yv, pv)\n",
    "    yhat = (pv >= threshold).astype(int)\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "    acc = accuracy_score(yv, yhat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(yv, yhat, average=\"binary\", zero_division=0)\n",
    "    print(f\"[NN Validation] AUC={auc:.4f} F1={f1:.4f} Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f}\")\n",
    "    return {\"AUC\":auc, \"F1\":f1, \"Acc\":acc, \"Prec\":prec, \"Rec\":rec}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ecf9f016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Using NN median threshold ==\n",
      "[NN Validation] AUC=0.7700 F1=0.6000 Acc=0.6000 Prec=0.6000 Rec=0.6000\n",
      "== Using LR threshold (from Part 1) ==\n",
      "[NN Validation] AUC=0.7700 F1=0.6000 Acc=0.6000 Prec=0.6000 Rec=0.6000\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "nn_adapter = FoldEnsembleAdapter(fold_paths, CFG, device)\n",
    "\n",
    "print(\"== Using NN median threshold ==\")\n",
    "_ = evaluate_validation_with_nn(VAL_JSONL, nn_adapter, final_thr_nn)\n",
    "\n",
    "print(\"== Using LR threshold (from Part 1) ==\")\n",
    "_ = evaluate_validation_with_nn(VAL_JSONL, nn_adapter, summary[\"final_thr\"])  # from Part 1 baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e8e3ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote submission: submission_nn.csv\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def nn_test_inference_and_submit(test_jsonl_path, adapter, threshold, out_csv_path):\n",
    "    items = load_jsonl_features(test_jsonl_path)\n",
    "    test_ds = ParagraphDataset(items, y=None, max_len=CFG[\"max_len\"])\n",
    "    test_loader = make_loader(test_ds, CFG[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    pt = adapter._predict_loader(test_loader)\n",
    "    yhat = (pt >= threshold).astype(int)\n",
    "\n",
    "    df = pd.DataFrame({\"id\": [obj[\"id\"] for obj in items], \"label\": yhat})\n",
    "    df.to_csv(out_csv_path, index=False)\n",
    "    print(\"Wrote submission:\", out_csv_path)\n",
    "    return df\n",
    "\n",
    "# Choose a threshold for NN (median of fold bests is a good start)\n",
    "SUBMISSION_PATH_NN = Path(\"./submission_nn.csv\")\n",
    "_ = nn_test_inference_and_submit(TEST_JSONL, nn_adapter, final_thr_nn, SUBMISSION_PATH_NN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7b2ab688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: submission_nn_prob.csv\n"
     ]
    }
   ],
   "source": [
    "def nn_prob_submission(test_jsonl_path, nn_adapter, out_csv_path):\n",
    "    items = load_jsonl_features(test_jsonl_path)\n",
    "    test_ds = ParagraphDataset(items, y=None, max_len=CFG[\"max_len\"])\n",
    "    test_loader = make_loader(test_ds, CFG[\"batch_size\"], shuffle=False)\n",
    "    y_prob = nn_adapter._predict_loader(test_loader)\n",
    "    pd.DataFrame({\"id\": [o[\"id\"] for o in items], \"y_prob\": y_prob}).to_csv(out_csv_path, index=False)\n",
    "    print(\"Wrote:\", out_csv_path)\n",
    "\n",
    "SUBMISSION_NN_PROB = Path(\"./submission_nn_prob.csv\")\n",
    "nn_prob_submission(TEST_JSONL, nn_adapter, SUBMISSION_NN_PROB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "53c47e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: submission_mmd_prob.csv\n"
     ]
    }
   ],
   "source": [
    "def meta_prob_submission(test_jsonl_path, base_model, meta_model, out_csv_path):\n",
    "    items = load_jsonl_features(test_jsonl_path)\n",
    "    dft = to_paragraph_matrix_from_jsonl_items(items)\n",
    "    Xt = np.stack(dft[\"vector\"].values)\n",
    "    p_base = base_model.predict_proba(Xt)[:, 1]\n",
    "    feat = mmd_features_batch(Xt, BANK_AI, BANK_HU, gamma, mAA, mHH)\n",
    "    feat[\"p_base\"] = p_base\n",
    "    Xf = feat[[\"p_base\",\"k_xA\",\"k_xH\",\"diff_xA_xH\",\"glob_mAA_mHH\"]].values\n",
    "    y_prob = meta_full.predict_proba(Xf)[:, 1]\n",
    "    pd.DataFrame({\"id\": dft[\"id\"], \"y_prob\": y_prob}).to_csv(out_csv_path, index=False)\n",
    "    print(\"Wrote:\", out_csv_path)\n",
    "\n",
    "SUBMISSION_MMD_PROB = Path(\"./submission_mmd_prob.csv\")\n",
    "meta_prob_submission(TEST_JSONL, final_model, meta_full, SUBMISSION_MMD_PROB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5befff48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Blend sanity check (alpha=0.5) ==\n",
      "[Blend @alpha=0.5] AUC=0.8200 F1=0.7826 Acc=0.7500 Prec=0.6923 Rec=0.9000 Thr=0.094\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def blended_validation(val_jsonl_path, scikit_model, scikit_thr, nn_adapter, nn_thr, alpha=0.5):\n",
    "    if not Path(val_jsonl_path).exists():\n",
    "        print(\"No validation file found. Skipping.\")\n",
    "        return None\n",
    "    items = load_jsonl_features(val_jsonl_path)\n",
    "    val_ds = ParagraphDataset(items, y=None, max_len=CFG[\"max_len\"])\n",
    "    val_loader = make_loader(val_ds, CFG[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    # labels\n",
    "    labels = [int(obj.get(\"label\", 0)) for obj in read_jsonl(val_jsonl_path)]\n",
    "    yv = np.array(labels, dtype=np.int64)\n",
    "\n",
    "    # probs from baseline (mean-pooled)\n",
    "    dfv = to_paragraph_matrix_from_jsonl_items(items)\n",
    "    Xv = np.stack(dfv[\"vector\"].values)\n",
    "    pb = scikit_model.predict_proba(Xv)[:, 1]\n",
    "\n",
    "    # probs from NN\n",
    "    pn = nn_adapter._predict_loader(val_loader)\n",
    "\n",
    "    p = alpha*pn + (1-alpha)*pb\n",
    "\n",
    "    # pick threshold by simple scan (or blend of thresholds)\n",
    "    best_t, best_f1 = 0.5, -1\n",
    "    for t in np.linspace(0.01, 0.99, 199):\n",
    "        f1 = f1_score(yv, (p >= t).astype(int))\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, precision_recall_fscore_support\n",
    "    auc = roc_auc_score(yv, p)\n",
    "    yhat = (p >= best_t).astype(int)\n",
    "    acc = accuracy_score(yv, yhat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(yv, yhat, average=\"binary\", zero_division=0)\n",
    "    print(f\"[Blend @alpha={alpha}] AUC={auc:.4f} F1={f1:.4f} Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} Thr={best_t:.3f}\")\n",
    "    return dict(AUC=auc, F1=f1, Acc=acc, Prec=prec, Rec=rec, Thr=best_t)\n",
    "\n",
    "print(\"== Blend sanity check (alpha=0.5) ==\")\n",
    "_ = blended_validation(VAL_JSONL, final_model, summary[\"final_thr\"], nn_adapter, final_thr_nn, alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90adba10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d661188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a64bea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "46c522fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Part 3 — Relative-test (MMD) features + Meta-classifier\n",
    "\n",
    "# %%\n",
    "import numpy as np, pandas as pd, json, joblib, gc\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "MMD_DIR = MODELS_DIR / \"mmd_v1\"\n",
    "MMD_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MMD_CFG = {\n",
    "    \"bank_size\": 512,     # per class; reduce to 256 if RAM is tight\n",
    "    \"subset_for_sigma\": 4000,  # how many points to use for median heuristic\n",
    "    \"seed\": SEED\n",
    "}\n",
    "json.dump(MMD_CFG, open(MMD_DIR / \"config.json\", \"w\"))\n",
    "rng = np.random.default_rng(MMD_CFG[\"seed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a847dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bank size per class: 512 | sigma=2.290693 | gamma=0.095288 | mAA=0.443174 | mHH=0.457128\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def rbf_kernel_dot(a, b, gamma):\n",
    "    \"\"\"\n",
    "    Fast RBF via ||a-b||^2 = ||a||^2 + ||b||^2 - 2 a b^T\n",
    "    a: (n, d), b: (m, d) -> K: (n, m)\n",
    "    \"\"\"\n",
    "    a2 = (a*a).sum(axis=1, keepdims=True)   # (n,1)\n",
    "    b2 = (b*b).sum(axis=1, keepdims=True).T # (1,m)\n",
    "    d2 = a2 + b2 - 2.0 * (a @ b.T)\n",
    "    return np.exp(-gamma * np.clip(d2, 0.0, None))\n",
    "\n",
    "def median_heuristic_sigma(X, n_subset=4000):\n",
    "    n = len(X)\n",
    "    idx = rng.choice(n, size=min(n_subset, n), replace=False)\n",
    "    S = X[idx]\n",
    "    # sample pairs for robustness\n",
    "    jdx = rng.choice(len(S), size=min(2000, len(S)), replace=False)\n",
    "    P = S[jdx]\n",
    "    Q = S[rng.choice(len(S), size=len(jdx), replace=False)]\n",
    "    d2 = ((P-Q)**2).sum(axis=1)\n",
    "    sigma = np.sqrt(np.median(d2) / 2.0) + 1e-8\n",
    "    return float(sigma)\n",
    "\n",
    "# Build pooled train if not available\n",
    "# (You already have X: (n, 768) from Part 1)\n",
    "assert X.shape[1] == 768 and len(X) == len(y)\n",
    "\n",
    "# Stratified sample banks\n",
    "ai_idx = np.where(y==1)[0]\n",
    "hu_idx = np.where(y==0)[0]\n",
    "rng.shuffle(ai_idx); rng.shuffle(hu_idx)\n",
    "\n",
    "K = min(MMD_CFG[\"bank_size\"], len(ai_idx), len(hu_idx))\n",
    "BANK_AI = X[ai_idx[:K]]\n",
    "BANK_HU = X[hu_idx[:K]]\n",
    "\n",
    "# Kernel bandwidth (median heuristic on full train or subset)\n",
    "sigma = median_heuristic_sigma(X, n_subset=MMD_CFG[\"subset_for_sigma\"])\n",
    "gamma = 1.0 / (2.0 * sigma * sigma)\n",
    "\n",
    "# Precompute class self-similarity means (excluding diagonal)\n",
    "def offdiag_mean_selfsim(B, gamma):\n",
    "    Kmat = rbf_kernel_dot(B, B, gamma)\n",
    "    n = Kmat.shape[0]\n",
    "    s = (Kmat.sum() - np.trace(Kmat)) / (n*(n-1))\n",
    "    return float(s)\n",
    "\n",
    "mAA = offdiag_mean_selfsim(BANK_AI, gamma)\n",
    "mHH = offdiag_mean_selfsim(BANK_HU, gamma)\n",
    "\n",
    "# Persist banks & params\n",
    "np.save(MMD_DIR / \"bank_ai.npy\", BANK_AI)\n",
    "np.save(MMD_DIR / \"bank_hu.npy\", BANK_HU)\n",
    "json.dump({\"sigma\": sigma, \"gamma\": gamma, \"mAA\": mAA, \"mHH\": mHH, \"K\": K},\n",
    "          open(MMD_DIR / \"kernel.json\", \"w\"))\n",
    "print(f\"Bank size per class: {K} | sigma={sigma:.6f} | gamma={gamma:.6f} | mAA={mAA:.6f} | mHH={mHH:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b300cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def mmd_features_batch(Z, bank_ai, bank_hu, gamma, mAA, mHH):\n",
    "    \"\"\"\n",
    "    Z: (n, 768) pooled vectors\n",
    "    Returns DataFrame with:\n",
    "      k_xA = mean RBF(x, A)\n",
    "      k_xH = mean RBF(x, H)\n",
    "      diff = k_xA - k_xH   (positive => closer to AI)\n",
    "      glob = mAA - mHH     (same for all x; keeps the \"relative test\" flavor)\n",
    "    \"\"\"\n",
    "    KA = rbf_kernel_dot(Z, bank_ai, gamma)   # (n, K)\n",
    "    KH = rbf_kernel_dot(Z, bank_hu, gamma)   # (n, K)\n",
    "    k_xA = KA.mean(axis=1)\n",
    "    k_xH = KH.mean(axis=1)\n",
    "    diff = k_xA - k_xH\n",
    "    glob = np.full_like(diff, fill_value=(mAA - mHH))\n",
    "    return pd.DataFrame({\n",
    "        \"k_xA\": k_xA, \"k_xH\": k_xH, \"diff_xA_xH\": diff, \"glob_mAA_mHH\": glob\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4702b5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[META Fold 1] AUC=0.9680 F1@best=0.9079 thr=0.569\n",
      "[META Fold 2] AUC=0.9654 F1@best=0.9033 thr=0.421\n",
      "[META Fold 3] AUC=0.9648 F1@best=0.9058 thr=0.441\n",
      "[META Fold 4] AUC=0.9637 F1@best=0.9034 thr=0.436\n",
      "[META Fold 5] AUC=0.9681 F1@best=0.9060 thr=0.460\n",
      "\n",
      "[META OOF] AUC=0.96526 F1=0.9051 Acc=0.9034 Prec=0.8897 Rec=0.9211 Thr=0.441\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# You already have: oof_pred (baseline OOF probabilities), X (pooled train), y\n",
    "feat_train = mmd_features_batch(X, BANK_AI, BANK_HU, gamma, mAA, mHH)\n",
    "feat_train[\"p_base\"] = oof_pred  # from Part 1 CV\n",
    "\n",
    "cols = [\"p_base\", \"k_xA\", \"k_xH\", \"diff_xA_xH\", \"glob_mAA_mHH\"]\n",
    "feat_train_arr = feat_train[cols].values\n",
    "\n",
    "# Train meta model with honest OOF\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "oof_meta = np.zeros(len(y), dtype=np.float32)\n",
    "thr_list, folds_meta = [], []\n",
    "\n",
    "for fold, (tr, va) in enumerate(skf.split(feat_train_arr, y), 1):\n",
    "    Xtr, Xva = feat_train_arr[tr], feat_train_arr[va]\n",
    "    ytr, yva = y[tr], y[va]\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            penalty=\"l2\", solver=\"lbfgs\", max_iter=2000, C=1.0, random_state=SEED))\n",
    "    ])\n",
    "    meta = CalibratedClassifierCV(estimator=pipe, method=\"isotonic\", cv=3)\n",
    "    meta.fit(Xtr, ytr)\n",
    "    pva = meta.predict_proba(Xva)[:,1]\n",
    "    oof_meta[va] = pva\n",
    "\n",
    "    # pick F1-optimal threshold on this fold\n",
    "    best_t, best_f1 = 0.5, -1\n",
    "    for t in np.linspace(0.01, 0.99, 199):\n",
    "        f1 = f1_score(yva, (pva>=t).astype(int))\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_t = f1, t\n",
    "    thr_list.append(float(best_t))\n",
    "    auc = roc_auc_score(yva, pva)\n",
    "    print(f\"[META Fold {fold}] AUC={auc:.4f} F1@best={best_f1:.4f} thr={best_t:.3f}\")\n",
    "\n",
    "auc_oof = roc_auc_score(y, oof_meta)\n",
    "t_star = float(np.median(thr_list))\n",
    "pred_lbl = (oof_meta >= t_star).astype(int)\n",
    "acc = accuracy_score(y, pred_lbl)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y, pred_lbl, average=\"binary\")\n",
    "print(f\"\\n[META OOF] AUC={auc_oof:.5f} F1={f1:.4f} Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} Thr={t_star:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67e0ab97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: models/mmd_v1/meta_model.pkl models/mmd_v1/meta_model.json\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Fit on ALL data\n",
    "pipe_full = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        penalty=\"l2\", solver=\"lbfgs\", max_iter=3000, C=1.0, random_state=SEED))\n",
    "])\n",
    "meta_full = CalibratedClassifierCV(estimator=pipe_full, method=\"isotonic\", cv=5)\n",
    "meta_full.fit(feat_train_arr, y)\n",
    "\n",
    "# Decide final threshold (use OOF-median t_star; optionally nudge by -0.02 ~ -0.05)\n",
    "t_chosen = max(0.0, t_star - 0.02)\n",
    "\n",
    "joblib.dump(meta_full, MMD_DIR / \"meta_model.pkl\")\n",
    "feat_train.sample(3, random_state=SEED)[:0]  # no-op to anchor variable in notebook\n",
    "\n",
    "json.dump({\n",
    "    \"cols\": cols, \"thr_oof\": t_star, \"thr_chosen\": t_chosen,\n",
    "    \"uses\": \"p_base + MMD features (k_xA,k_xH,diff,glob)\"\n",
    "}, open(MMD_DIR / \"meta_model.json\", \"w\"))\n",
    "\n",
    "print(\"Saved:\", MMD_DIR / \"meta_model.pkl\", MMD_DIR / \"meta_model.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be7f3f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[META Validation] AUC=0.9600 F1=0.6667 Acc=0.7500 Prec=1.0000 Rec=0.5000 Thr=0.421\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def features_from_jsonl_for_meta(val_jsonl_path):\n",
    "    items = load_jsonl_features(val_jsonl_path)\n",
    "    # baseline prob on pooled features\n",
    "    dfv = to_paragraph_matrix_from_jsonl_items(items)\n",
    "    Xv = np.stack(dfv[\"vector\"].values)\n",
    "\n",
    "    # baseline calibrated prob (from your Part 1 final_model)\n",
    "    p_base = final_model.predict_proba(Xv)[:,1]\n",
    "\n",
    "    # MMD features\n",
    "    feat = mmd_features_batch(Xv, BANK_AI, BANK_HU, gamma, mAA, mHH)\n",
    "    feat[\"p_base\"] = p_base\n",
    "    return np.array([int(o.get(\"label\",0)) for o in read_jsonl(val_jsonl_path)]), feat, [obj[\"id\"] for obj in items]\n",
    "\n",
    "def evaluate_meta_on_validation(val_jsonl_path, meta_model, thr):\n",
    "    if not Path(val_jsonl_path).exists():\n",
    "        print(\"No validation file.\")\n",
    "        return None\n",
    "    yv, feat_df, _ = features_from_jsonl_for_meta(val_jsonl_path)\n",
    "    Xf = feat_df[cols].values\n",
    "    pv = meta_model.predict_proba(Xf)[:,1]\n",
    "    auc = roc_auc_score(yv, pv)\n",
    "    yhat = (pv >= thr).astype(int)\n",
    "    acc = accuracy_score(yv, yhat)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(yv, yhat, average=\"binary\", zero_division=0)\n",
    "    print(f\"[META Validation] AUC={auc:.4f} F1={f1:.4f} Acc={acc:.4f} Prec={prec:.4f} Rec={rec:.4f} Thr={thr:.3f}\")\n",
    "    return {\"AUC\":auc, \"F1\":f1, \"Acc\":acc, \"Prec\":prec, \"Rec\":rec}\n",
    "\n",
    "_ = evaluate_meta_on_validation(VAL_JSONL, meta_full, t_chosen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac30685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote submission: submission_mmd.csv\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "def meta_test_and_submit(test_jsonl_path, meta_model, thr, out_csv):\n",
    "    items = load_jsonl_features(test_jsonl_path)\n",
    "    # pooled vectors\n",
    "    dft = to_paragraph_matrix_from_jsonl_items(items)\n",
    "    Xt = np.stack(dft[\"vector\"].values)\n",
    "\n",
    "    # baseline probs\n",
    "    p_base = final_model.predict_proba(Xt)[:,1]\n",
    "\n",
    "    # MMD features\n",
    "    feat = mmd_features_batch(Xt, BANK_AI, BANK_HU, gamma, mAA, mHH)\n",
    "    feat[\"p_base\"] = p_base\n",
    "    Xf = feat[cols].values\n",
    "\n",
    "    pt = meta_model.predict_proba(Xf)[:,1]\n",
    "    yhat = (pt >= thr).astype(int)\n",
    "\n",
    "    sub = pd.DataFrame({\"id\": dft[\"id\"], \"label\": yhat})\n",
    "    sub.to_csv(out_csv, index=False)\n",
    "    print(\"Wrote submission:\", out_csv)\n",
    "    return sub\n",
    "\n",
    "SUBMISSION_PATH_MMD = Path(\"./submission_mmd.csv\")\n",
    "_ = meta_test_and_submit(TEST_JSONL, meta_full, t_chosen, SUBMISSION_PATH_MMD)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8191d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 3-way blend (alpha=0.35, beta=0.35) prob submission: submission_blend3_prob.csv\n"
     ]
    }
   ],
   "source": [
    "# === 3-way blend probability submission: id,y_prob ===\n",
    "def blend3_prob_submission(test_jsonl_path, base_model, nn_adapter, meta_model, alpha, beta, out_csv_path):\n",
    "    # alpha = weight for NN, beta = weight for MMD meta, (1-alpha-beta) for baseline\n",
    "    items = load_jsonl_features(test_jsonl_path)\n",
    "\n",
    "    # baseline probs\n",
    "    dft = to_paragraph_matrix_from_jsonl_items(items)\n",
    "    Xt = np.stack(dft[\"vector\"].values)\n",
    "    pb = base_model.predict_proba(Xt)[:, 1]\n",
    "\n",
    "    # NN probs\n",
    "    test_ds = ParagraphDataset(items, y=None, max_len=CFG[\"max_len\"])\n",
    "    test_loader = make_loader(test_ds, CFG[\"batch_size\"], shuffle=False)\n",
    "    pn = nn_adapter._predict_loader(test_loader)\n",
    "\n",
    "    # meta probs\n",
    "    feat = mmd_features_batch(Xt, BANK_AI, BANK_HU, gamma, mAA, mHH)\n",
    "    feat[\"p_base\"] = pb\n",
    "    Xf = feat[[\"p_base\",\"k_xA\",\"k_xH\",\"diff_xA_xH\",\"glob_mAA_mHH\"]].values\n",
    "    pm = meta_model.predict_proba(Xf)[:, 1]\n",
    "\n",
    "    y_prob = (1 - alpha - beta) * pb + alpha * pn + beta * pm\n",
    "    sub = pd.DataFrame({\"id\": dft[\"id\"], \"y_prob\": y_prob})\n",
    "    sub.to_csv(out_csv_path, index=False)\n",
    "    print(f\"Wrote 3-way blend (alpha={alpha}, beta={beta}) prob submission:\", out_csv_path)\n",
    "    return sub\n",
    "\n",
    "SUBMISSION_BLEND3_PROB = Path(\"./submission_blend3_prob.csv\")\n",
    "_ = blend3_prob_submission(TEST_JSONL, final_model, nn_adapter, meta_full,\n",
    "                           alpha=0.35, beta=0.35, out_csv_path=SUBMISSION_BLEND3_PROB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d74dec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val AUC: 0.99 | weights NN/ MMD/ Base = 0.0 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# get validation probs from each model\n",
    "items_val = load_jsonl_features(VAL_JSONL)\n",
    "dfv_val = to_paragraph_matrix_from_jsonl_items(items_val)\n",
    "Xv = np.stack(dfv_val[\"vector\"].values)\n",
    "yv = np.array([int(o.get(\"label\", 0)) for o in read_jsonl(VAL_JSONL)], dtype=np.int64)\n",
    "\n",
    "# baseline probs\n",
    "pb = final_model.predict_proba(Xv)[:, 1]\n",
    "\n",
    "# NN probs\n",
    "val_ds = ParagraphDataset(items_val, y=None, max_len=CFG[\"max_len\"])\n",
    "val_loader = make_loader(val_ds, CFG[\"batch_size\"], shuffle=False)\n",
    "pn = nn_adapter._predict_loader(val_loader)\n",
    "\n",
    "# MMD probs\n",
    "featv = mmd_features_batch(Xv, BANK_AI, BANK_HU, gamma, mAA, mHH)\n",
    "featv[\"p_base\"] = pb\n",
    "pm = meta_full.predict_proba(featv[[\"p_base\",\"k_xA\",\"k_xH\",\"diff_xA_xH\",\"glob_mAA_mHH\"]].values)[:,1]\n",
    "\n",
    "# grid search weights (alpha for NN, beta for MMD, 1-alpha-beta for baseline)\n",
    "best = (-1, None)\n",
    "for a, b in product(np.linspace(0,1,21), repeat=2):\n",
    "    if a + b > 1: continue\n",
    "    p = (1 - a - b)*pb + a*pn + b*pm\n",
    "    auc = roc_auc_score(yv, p)\n",
    "    if auc > best[0]:\n",
    "        best = (auc, (a, b, 1 - a - b))\n",
    "best_auc, (alpha, beta, gamma_w) = best\n",
    "print(\"Best val AUC:\", round(best_auc, 5), \"| weights NN/ MMD/ Base =\", alpha, beta, gamma_w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57da0474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote blend: submission_blend3_prob.csv\n"
     ]
    }
   ],
   "source": [
    "def blend3_prob_submission(test_jsonl_path, base_model, nn_adapter, meta_model, alpha, beta, out_csv_path):\n",
    "    items = load_jsonl_features(test_jsonl_path)\n",
    "    dft = to_paragraph_matrix_from_jsonl_items(items)\n",
    "    Xt = np.stack(dft[\"vector\"].values)\n",
    "\n",
    "    pb = base_model.predict_proba(Xt)[:, 1]\n",
    "    test_ds = ParagraphDataset(items, y=None, max_len=CFG[\"max_len\"])\n",
    "    test_loader = make_loader(test_ds, CFG[\"batch_size\"], shuffle=False)\n",
    "    pn = nn_adapter._predict_loader(test_loader)\n",
    "\n",
    "    feat = mmd_features_batch(Xt, BANK_AI, BANK_HU, gamma, mAA, mHH)\n",
    "    feat[\"p_base\"] = pb\n",
    "    pm = meta_model.predict_proba(feat[[\"p_base\",\"k_xA\",\"k_xH\",\"diff_xA_xH\",\"glob_mAA_mHH\"]].values)[:,1]\n",
    "\n",
    "    y_prob = (1 - alpha - beta)*pb + alpha*pn + beta*pm\n",
    "    pd.DataFrame({\"id\": dft[\"id\"], \"y_prob\": y_prob}).to_csv(out_csv_path, index=False)\n",
    "    print(\"Wrote blend:\", out_csv_path)\n",
    "\n",
    "SUBMISSION_BLEND3_PROB = Path(\"./submission_blend3_prob.csv\")\n",
    "blend3_prob_submission(TEST_JSONL, final_model, nn_adapter, meta_full, alpha=alpha, beta=beta, out_csv_path=SUBMISSION_BLEND3_PROB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeeadb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa44fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34853c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78754729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507c08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a0d24c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5dc2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a3e8d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "516f4f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd0f88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
